{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 04: MCP (Model Context Protocol) Tools\n",
    "\n",
    "## üéØ What is This Notebook About?\n",
    "\n",
    "Welcome to Notebook 04! In this notebook, we'll explore **MCP (Model Context Protocol)** - a protocol for integrating external tools and services with LLMs.\n",
    "\n",
    "**What we'll learn:**\n",
    "1. **What is MCP** - Understanding the Model Context Protocol\n",
    "2. **Creating Agents with MCP Tools** - How to configure agents with MongoDB MCP tools\n",
    "3. **Agent Inference** - How to query agents and see them use tools\n",
    "4. **Understanding Tool Execution** - How agents call tools and use results\n",
    "\n",
    "**Why this matters:**\n",
    "- LLMs can't directly interact with systems\n",
    "- MCP provides a standardized way to connect tools\n",
    "- Enables agents to take real actions\n",
    "- Makes agents more powerful and useful\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- ‚úÖ Understand what MCP is and why it's important\n",
    "- ‚úÖ Know how to create agents with MCP toolgroups\n",
    "- ‚úÖ Learn how to query agents and retrieve responses\n",
    "- ‚úÖ See how agents automatically use tools when needed\n",
    "- ‚úÖ Understand the agent inference workflow\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Prerequisites\n",
    "\n",
    "- LlamaStack server running on OpenShift (see Module README)\n",
    "- MongoDB MCP server deployed and registered (see OpenShift docs)\n",
    "- Python environment with dependencies installed\n",
    "- Understanding of Notebook 03 (LlamaStack Core Features)\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Setup\n",
    "\n",
    "Let's start by connecting to LlamaStack and verifying everything is working.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import subprocess\n",
    "import time\n",
    "import httpx\n",
    "import urllib3\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "# Suppress SSL warnings for OpenShift self-signed certificates\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "# ============================================================================\n",
    "# Configuration - Update these values for your OpenShift deployment\n",
    "# ============================================================================\n",
    "\n",
    "def get_llamastack_url() -> str:\n",
    "    \"\"\"Get LlamaStack URL from environment or OpenShift route\"\"\"\n",
    "    # Check environment variable first\n",
    "    url = os.getenv(\"LLAMA_STACK_URL\")\n",
    "    if url:\n",
    "        return url.rstrip(\"/\")\n",
    "    \n",
    "    # Try to get from OpenShift route\n",
    "    namespace = os.getenv(\"NAMESPACE\", \"my-first-model\")\n",
    "    \n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"oc\", \"get\", \"route\", \"llamastack-route\", \"-n\", namespace,\n",
    "             \"-o\", \"jsonpath={.spec.host}\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        if result.returncode == 0 and result.stdout:\n",
    "            return f\"https://{result.stdout.strip()}\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Fallback to localhost\n",
    "    return \"http://localhost:8321\"\n",
    "\n",
    "# Get LlamaStack URL\n",
    "llamastack_url = get_llamastack_url()\n",
    "\n",
    "# Model identifier - Use the full identifier from LlamaStack\n",
    "model = os.getenv(\"LLAMA_MODEL\", \"vllm-inference/llama-32-3b-instruct\")\n",
    "\n",
    "print(f\"üì° LlamaStack URL: {llamastack_url}\")\n",
    "print(f\"ü§ñ Model: {model}\")\n",
    "\n",
    "# Initialize LlamaStack client\n",
    "client = LlamaStackClient(base_url=llamastack_url)\n",
    "\n",
    "# Verify connection\n",
    "try:\n",
    "    models = client.models.list()\n",
    "    model_count = len(models.data) if hasattr(models, 'data') else len(models)\n",
    "    print(f\"\\n‚úÖ Connected to LlamaStack\")\n",
    "    print(f\"   Available models: {model_count}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Cannot connect to LlamaStack: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    print(\"   1. Check if route exists: oc get route llamastack-route -n my-first-model\")\n",
    "    print(\"   2. Update llamastack_url variable above with your route URL\")\n",
    "    print(\"   3. Or set LLAMA_STACK_URL environment variable:\")\n",
    "    print(\"      export LLAMA_STACK_URL='https://<route-host>'\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Understanding MCP (Model Context Protocol)\n",
    "\n",
    "**What we're doing:** Understanding MCP - the protocol that lets agents interact with external systems.\n",
    "\n",
    "**Why:** LLMs are just text processors - they can't directly interact with systems. MCP provides a standardized way to connect tools, so agents can actually DO things, not just talk about them!\n",
    "\n",
    "### What is MCP?\n",
    "\n",
    "**MCP (Model Context Protocol)** is a protocol for integrating external tools and services with LLMs. It allows agents to:\n",
    "- **Call external APIs** (e.g., check service status, restart services)\n",
    "- **Access databases** (e.g., query MongoDB collections)\n",
    "- **Execute commands** (e.g., run system commands)\n",
    "- **Integrate with other systems** (e.g., monitoring tools, ticketing systems)\n",
    "\n",
    "**Why MCP matters:**\n",
    "- LLMs can't directly interact with systems (they're text processors, not system operators!)\n",
    "- MCP provides a standardized way to connect tools (one protocol, many tools)\n",
    "- Enables agents to take real actions (check status, query databases, execute commands)\n",
    "- Makes agents more powerful and useful (from assistant to operator!)\n",
    "\n",
    "**MCP Architecture:**\n",
    "- **MCP Server**: Exposes tools, resources, and prompts (e.g., MongoDB MCP server)\n",
    "- **MCP Client (LlamaStack)**: Connects to MCP servers and makes tools available to agents\n",
    "- **Agent**: Uses tools exposed by MCP servers to take actions\n",
    "\n",
    "**In this notebook:** We'll use the MongoDB MCP server that's already deployed in OpenShift. The agent will automatically use MongoDB tools to query the database when needed!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Creating an Agent with MCP Tools\n",
    "\n",
    "**What we're doing:** Creating an agent that has access to MongoDB MCP tools.\n",
    "\n",
    "**Why:** Agents need to be configured with toolgroups to access MCP tools. Once configured, the agent can automatically decide when to use tools based on the user's query.\n",
    "\n",
    "**Key Points:**\n",
    "- `toolgroups`: List of MCP toolgroups the agent can use (e.g., `[\"mcp::mongodb\"]`)\n",
    "- `tool_choice`: Set to `\"auto\"` to let the agent decide when to use tools\n",
    "- `instructions`: Guide the agent on when and how to use tools\n",
    "- `sampling_params`: Control response generation (max_tokens, temperature, etc.)\n",
    "\n",
    "**The fun part:** Once created, the agent will automatically use MongoDB tools when you ask database-related questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with MongoDB MCP tools\n",
    "print(\"=\" * 60)\n",
    "print(\"Creating Agent with MongoDB MCP Tools\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "agent_config = {\n",
    "    \"model\": model,\n",
    "    \"instructions\": (\n",
    "        \"You have access to MongoDB through MCP tools. \"\n",
    "        \"Always use the MongoDB MCP tools to query the database when asked about databases or data.\"\n",
    "    ),\n",
    "    \"toolgroups\": [\"mcp::mongodb\"],  # Include MongoDB MCP toolgroup\n",
    "    \"tool_choice\": \"auto\",  # Let agent decide when to use tools\n",
    "    \"sampling_params\": {\n",
    "        \"max_tokens\": 2000  # Must be > 0!\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nüìã Agent Configuration:\")\n",
    "print(f\"   Model: {agent_config['model']}\")\n",
    "print(f\"   Toolgroups: {agent_config['toolgroups']}\")\n",
    "print(f\"   Tool Choice: {agent_config['tool_choice']}\")\n",
    "print(f\"   Max Tokens: {agent_config['sampling_params']['max_tokens']}\")\n",
    "\n",
    "# Create agent using alpha API\n",
    "try:\n",
    "    agent = client.alpha.agents.create(agent_config=agent_config)\n",
    "    print(f\"\\n‚úÖ Agent created successfully!\")\n",
    "    print(f\"   Agent ID: {agent.agent_id}\")\n",
    "    print(f\"\\nüí° This agent can now use MongoDB MCP tools!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating agent: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    print(\"   1. Make sure MongoDB MCP toolgroup is registered:\")\n",
    "    print(\"      Check: oc get toolgroups -n my-first-model\")\n",
    "    print(\"   2. Verify MongoDB MCP server is running:\")\n",
    "    print(\"      Check: oc get pods -n my-first-model | grep mongodb-mcp\")\n",
    "    print(\"   3. Register toolgroup if needed (see OpenShift docs)\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Creating a Session\n",
    "\n",
    "**What we're doing:** Creating a session for the agent to maintain conversation context.\n",
    "\n",
    "**Why:** Sessions allow agents to maintain context across multiple interactions. Each session is independent, so you can have multiple conversations with the same agent.\n",
    "\n",
    "**Key Points:**\n",
    "- Sessions maintain conversation history\n",
    "- Each session is independent (separate conversations)\n",
    "- Session names are optional but helpful for organization\n",
    "- Sessions persist until explicitly deleted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a session for the agent\n",
    "print(\"=\" * 60)\n",
    "print(\"Creating Session\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    session = client.alpha.agents.session.create(\n",
    "        agent_id=agent.agent_id,\n",
    "        session_name=\"mcp-tools-demo\"\n",
    "    )\n",
    "    print(f\"\\n‚úÖ Session created successfully!\")\n",
    "    print(f\"   Session ID: {session.session_id}\")\n",
    "    print(f\"   Session Name: {session.session_name if hasattr(session, 'session_name') else 'N/A'}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating session: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Querying the Agent\n",
    "\n",
    "**What we're doing:** Querying the agent and watching it use MongoDB MCP tools automatically.\n",
    "\n",
    "**Why:** This demonstrates the power of MCP - the agent automatically decides when to use tools based on your query. You don't need to explicitly tell it to use tools!\n",
    "\n",
    "**The Workflow:**\n",
    "1. **Send query** to the agent\n",
    "2. **Agent reasons** about the query\n",
    "3. **Agent decides** to use MongoDB tools (automatically!)\n",
    "4. **Agent calls** MongoDB MCP tools\n",
    "5. **Agent receives** tool results\n",
    "6. **Agent generates** response using real data\n",
    "\n",
    "**The fun part:** Watch the agent think and act - it will automatically use MongoDB tools when you ask database questions!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert objects to dictionaries\n",
    "def to_dict(obj):\n",
    "    \"\"\"Convert object to dictionary\"\"\"\n",
    "    if isinstance(obj, dict):\n",
    "        return obj\n",
    "    if hasattr(obj, 'model_dump'):\n",
    "        return obj.model_dump()\n",
    "    if hasattr(obj, 'dict'):\n",
    "        return obj.dict()\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        return {k: v for k, v in obj.__dict__.items() if not k.startswith('_')}\n",
    "    return {}\n",
    "\n",
    "# Query the agent\n",
    "print(\"=\" * 60)\n",
    "print(\"Querying Agent\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "query = \"What collections are in the mcp_demo database?\"\n",
    "print(f\"\\nüë§ Query: {query}\\n\")\n",
    "\n",
    "# Create turn with streaming\n",
    "try:\n",
    "    turn_stream = client.alpha.agents.turn.create(\n",
    "        agent_id=agent.agent_id,\n",
    "        session_id=session.session_id,\n",
    "        messages=[{\"role\": \"user\", \"content\": query}],\n",
    "        stream=True\n",
    "    )\n",
    "    print(\"‚úÖ Turn created, streaming response...\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Error creating turn: {e}\")\n",
    "    raise\n",
    "\n",
    "# Extract turn_id from streaming response\n",
    "print(\"\\nüìã Extracting turn_id from stream...\")\n",
    "turn_id = None\n",
    "for chunk in turn_stream:\n",
    "    if hasattr(chunk, 'event') and chunk.event and hasattr(chunk.event, 'payload'):\n",
    "        payload = chunk.event.payload\n",
    "        d = to_dict(payload)\n",
    "        turn_id = d.get('turn_id')\n",
    "        if not turn_id and 'step_details' in d:\n",
    "            step_details = to_dict(d['step_details'])\n",
    "            turn_id = step_details.get('turn_id')\n",
    "        if turn_id:\n",
    "            break\n",
    "\n",
    "if turn_id:\n",
    "    print(f\"‚úÖ Turn ID: {turn_id}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Could not extract turn_id from stream\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Retrieving Turn Results\n",
    "\n",
    "**What we're doing:** Retrieving the complete turn results to see the agent's response and tool usage.\n",
    "\n",
    "**Why:** The streaming response gives us the turn_id, but we need to retrieve the full turn to see:\n",
    "- The agent's final response\n",
    "- Which tools were called\n",
    "- Tool arguments and results\n",
    "- Step-by-step execution details\n",
    "\n",
    "**Key Points:**\n",
    "- Wait a moment after streaming (turn needs time to complete)\n",
    "- Retrieve turn using the turn_id\n",
    "- Parse messages and steps to extract response\n",
    "- Check steps to see tool calls and results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve turn results\n",
    "import json\n",
    "\n",
    "if turn_id:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Retrieving Turn Results\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    print(\"\\n‚è≥ Waiting for turn to complete...\")\n",
    "    time.sleep(2)  # Give the turn time to complete\n",
    "    \n",
    "    try:\n",
    "        # Retrieve the turn\n",
    "        response = httpx.get(\n",
    "            f\"{llamastack_url}/v1alpha/agents/{agent.agent_id}/session/{session.session_id}/turn/{turn_id}\",\n",
    "            verify=False,\n",
    "            timeout=30\n",
    "        )\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Handle null response\n",
    "        if not response.text or response.text.strip() == 'null':\n",
    "            print(\"   ‚ö†Ô∏è  Turn not ready yet (response was null)\")\n",
    "            print(\"   üí° The turn may still be processing. Try waiting a bit longer.\")\n",
    "            data = None\n",
    "        else:\n",
    "            data = response.json()\n",
    "        \n",
    "        if data is None:\n",
    "            print(\"   ‚ö†Ô∏è  Could not retrieve turn data\")\n",
    "            print(\"   üí° This might mean the turn is still processing or the turn_id is incorrect\")\n",
    "        else:\n",
    "            print(\"‚úÖ Turn data retrieved successfully!\")\n",
    "            \n",
    "            # Extract messages and steps\n",
    "            messages = data.get('messages', [])\n",
    "            steps = data.get('steps', [])\n",
    "            \n",
    "            print(f\"\\nüìä Turn Summary:\")\n",
    "            print(f\"   Messages: {len(messages)}\")\n",
    "            print(f\"   Steps: {len(steps)}\")\n",
    "            \n",
    "            # Debug: Print all steps for full visibility\n",
    "            if steps:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(\"üì¶ Full Steps Debug (All Step Objects)\")\n",
    "                print(f\"{'='*60}\\n\")\n",
    "                \n",
    "                for i, step in enumerate(steps):\n",
    "                    step_type = step.get('type', '') or step.get('step_type', '')\n",
    "                    print(f\"{'='*60}\")\n",
    "                    print(f\"Step {i}: type='{step_type}'\")\n",
    "                    print(f\"{'='*60}\")\n",
    "                    print(json.dumps(step, indent=2, default=str))\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"\\n‚ö†Ô∏è  No steps found in turn data\")\n",
    "                print(\"\\nüì¶ Full Data Object (for debugging):\")\n",
    "                data_str = json.dumps(data, indent=2, default=str)\n",
    "                if len(data_str) > 2000:\n",
    "                    print(data_str[:2000] + \"...\")\n",
    "                else:\n",
    "                    print(data_str)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error retrieving turn: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        data = None\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Cannot retrieve turn results without turn_id\")\n",
    "    data = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Analyzing Tool Usage\n",
    "\n",
    "**What we're doing:** Examining the turn steps to see which tools were called and how they were used.\n",
    "\n",
    "**Why:** Understanding tool usage helps you:\n",
    "- See what the agent decided to do\n",
    "- Verify tools were called correctly\n",
    "- Debug issues with tool execution\n",
    "- Understand the agent's reasoning process\n",
    "\n",
    "**What to look for:**\n",
    "- **tool_call** steps: Show which tools were called and with what arguments\n",
    "- **tool_result** steps: Show the results returned by tools\n",
    "- **inference** steps: Show the agent's reasoning and final response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tool usage from steps (tool-specific only)\n",
    "import json\n",
    "\n",
    "if data:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Analyzing Tool Usage\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    steps = data.get('steps', [])\n",
    "    \n",
    "    if steps:\n",
    "        # Filter and show only tool-related steps\n",
    "        tool_steps = []\n",
    "        for i, step in enumerate(steps):\n",
    "            step_type = step.get('type', '') or step.get('step_type', '')\n",
    "            \n",
    "            # Check for tool calls in inference steps\n",
    "            if step_type == 'inference':\n",
    "                model_response = step.get('model_response', {})\n",
    "                tool_calls = model_response.get('tool_calls', [])\n",
    "                if tool_calls:\n",
    "                    tool_steps.append((i, step, 'tool_call', tool_calls))\n",
    "            \n",
    "            # Check for tool execution steps\n",
    "            if step_type == 'tool_execution':\n",
    "                tool_execution = step.get('tool_execution', {})\n",
    "                if tool_execution:\n",
    "                    tool_steps.append((i, step, 'tool_execution', tool_execution))\n",
    "            \n",
    "            # Check for tool result steps\n",
    "            if step_type == 'tool_result':\n",
    "                tool_result = step.get('tool_result', {})\n",
    "                if tool_result:\n",
    "                    tool_steps.append((i, step, 'tool_result', tool_result))\n",
    "        \n",
    "        if tool_steps:\n",
    "            print(f\"\\nüîß Found {len(tool_steps)} tool-related step(s):\\n\")\n",
    "            \n",
    "            for step_idx, step, tool_type, tool_data in tool_steps:\n",
    "                print(f\"{'='*60}\")\n",
    "                print(f\"Step {step_idx}: {tool_type}\")\n",
    "                print(f\"{'='*60}\")\n",
    "                \n",
    "                if tool_type == 'tool_call':\n",
    "                    print(\"\\nüìã Tool Calls from Inference Step:\")\n",
    "                    for tool_call in tool_data:\n",
    "                        call_id = tool_call.get('call_id', 'unknown')\n",
    "                        tool_name = tool_call.get('tool_name', 'unknown')\n",
    "                        arguments = tool_call.get('arguments', '{}')\n",
    "                        print(f\"\\n  üîß Tool: {tool_name}\")\n",
    "                        print(f\"     Call ID: {call_id}\")\n",
    "                        try:\n",
    "                            args_dict = json.loads(arguments) if isinstance(arguments, str) else arguments\n",
    "                            print(f\"     Arguments: {json.dumps(args_dict, indent=6)}\")\n",
    "                        except:\n",
    "                            print(f\"     Arguments: {arguments}\")\n",
    "                \n",
    "                elif tool_type == 'tool_execution':\n",
    "                    print(\"\\n‚öôÔ∏è  Tool Execution:\")\n",
    "                    tool_name = tool_data.get('tool_name', 'unknown')\n",
    "                    call_id = tool_data.get('call_id', 'unknown')\n",
    "                    print(f\"  Tool: {tool_name}\")\n",
    "                    print(f\"  Call ID: {call_id}\")\n",
    "                    if 'arguments' in tool_data:\n",
    "                        args = tool_data.get('arguments', {})\n",
    "                        print(f\"  Arguments: {json.dumps(args, indent=4, default=str)}\")\n",
    "                \n",
    "                elif tool_type == 'tool_result':\n",
    "                    print(\"\\nüì§ Tool Result:\")\n",
    "                    tool_name = tool_data.get('name', tool_data.get('tool_name', 'unknown'))\n",
    "                    result_content = tool_data.get('content', '')\n",
    "                    print(f\"  Tool: {tool_name}\")\n",
    "                    if result_content:\n",
    "                        result_str = str(result_content)\n",
    "                        if len(result_str) > 500:\n",
    "                            print(f\"  Result: {result_str[:500]}...\")\n",
    "                            print(f\"  (Full result: {len(result_str)} characters)\")\n",
    "                        else:\n",
    "                            print(f\"  Result: {result_str}\")\n",
    "                \n",
    "                print()\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  No tool-related steps found\")\n",
    "            print(\"   üí° The agent may not have used any tools, or tool information is in a different format\")\n",
    "            print(\"\\n   Available step types:\")\n",
    "            for i, step in enumerate(steps):\n",
    "                step_type = step.get('type', '') or step.get('step_type', '')\n",
    "                print(f\"     Step {i}: {step_type}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  No steps found in turn data\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No turn data available\")\n",
    "    print(\"   üí° Make sure Part 5 completed successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Extracting the Agent's Response\n",
    "\n",
    "**What we're doing:** Extracting the final response text from the turn data.\n",
    "\n",
    "**Why:** The agent's response might be in different places:\n",
    "- In the `messages` array (assistant messages)\n",
    "- In the `steps` array (inference steps with model_response)\n",
    "- We need to check both to find the complete response\n",
    "\n",
    "**Key Points:**\n",
    "- Check messages first (most common location)\n",
    "- Fall back to steps if not found in messages\n",
    "- Handle different content formats (string, list, dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the agent's response\n",
    "if data:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Extracting Agent Response\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    messages = data.get('messages', [])\n",
    "    steps = data.get('steps', [])\n",
    "    response_text = None\n",
    "    \n",
    "    # Try messages first\n",
    "    print(\"\\nüîç Checking messages...\")\n",
    "    for msg in reversed(messages):\n",
    "        if msg.get('role') == 'assistant':\n",
    "            content = msg.get('content', '')\n",
    "            if isinstance(content, str) and content.strip():\n",
    "                response_text = content\n",
    "                print(\"   ‚úÖ Found response in messages\")\n",
    "                break\n",
    "            elif isinstance(content, list) and content:\n",
    "                for item in content:\n",
    "                    if isinstance(item, dict):\n",
    "                        text = item.get('text', '')\n",
    "                        if text:\n",
    "                            response_text = text\n",
    "                            print(\"   ‚úÖ Found response in messages (list format)\")\n",
    "                            break\n",
    "                    elif isinstance(item, str) and item.strip():\n",
    "                        response_text = item\n",
    "                        print(\"   ‚úÖ Found response in messages (list format)\")\n",
    "                        break\n",
    "                if response_text:\n",
    "                    break\n",
    "    \n",
    "    # If not found in messages, check steps\n",
    "    if not response_text:\n",
    "        print(\"   ‚ö†Ô∏è  Not found in messages, checking steps...\")\n",
    "        for step in reversed(steps):\n",
    "            # Try inference step\n",
    "            if step.get('type') == 'inference' or step.get('step_type') == 'inference':\n",
    "                model_response = step.get('model_response', {})\n",
    "                content = model_response.get('content', '')\n",
    "                if isinstance(content, str) and content.strip():\n",
    "                    response_text = content\n",
    "                    print(\"   ‚úÖ Found response in inference step\")\n",
    "                    break\n",
    "            \n",
    "            # Try any step with model_response\n",
    "            if 'model_response' in step:\n",
    "                model_response = step.get('model_response', {})\n",
    "                content = model_response.get('content', '')\n",
    "                if isinstance(content, str) and content.strip():\n",
    "                    response_text = content\n",
    "                    print(\"   ‚úÖ Found response in step model_response\")\n",
    "                    break\n",
    "    \n",
    "    # Display the response\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Agent Response\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if response_text:\n",
    "        print(f\"\\nüí¨ {response_text}\\n\")\n",
    "        \n",
    "        # Show tools used\n",
    "        tools_used = []\n",
    "        for step in steps:\n",
    "            if step.get('type') == 'tool_call' or step.get('step_type') == 'tool_call':\n",
    "                tool_call = step.get('tool_call', {})\n",
    "                tool_name = tool_call.get('name', 'unknown')\n",
    "                if tool_name not in tools_used:\n",
    "                    tools_used.append(tool_name)\n",
    "        \n",
    "        if tools_used:\n",
    "            print(f\"üîß Tools used: {', '.join(tools_used)}\\n\")\n",
    "        else:\n",
    "            print(\"üí° No tools were used in this response\\n\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Could not extract response text\")\n",
    "        print(\"   üí° The turn may still be processing, or response format is unexpected\")\n",
    "        print(\"   üí° Check the steps above for more details\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Testing Multiple Queries\n",
    "\n",
    "**What we're doing:** Testing the agent with different queries to see how it uses MongoDB tools.\n",
    "\n",
    "**Why:** Different queries will trigger different tool calls. This helps you understand:\n",
    "- When the agent decides to use tools\n",
    "- Which tools are called for different queries\n",
    "- How the agent combines tool results into responses\n",
    "\n",
    "**Try different queries:**\n",
    "- \"What databases are available?\"\n",
    "- \"How many documents are in the incidents collection?\"\n",
    "- \"What are the fields in the incidents collection?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with multiple queries\n",
    "import json\n",
    "\n",
    "def extract_tools_from_steps(steps):\n",
    "    \"\"\"Extract tool names from steps (checking both tool_execution and inference steps)\"\"\"\n",
    "    tools_used = []\n",
    "    for step in steps:\n",
    "        step_type = step.get('type', '') or step.get('step_type', '')\n",
    "        \n",
    "        # Check tool_execution steps\n",
    "        if step_type == 'tool_execution':\n",
    "            tool_execution = step.get('tool_execution', {})\n",
    "            tool_name = tool_execution.get('tool_name', '')\n",
    "            if tool_name and tool_name not in tools_used:\n",
    "                tools_used.append(tool_name)\n",
    "        \n",
    "        # Check inference steps for tool_calls\n",
    "        elif step_type == 'inference':\n",
    "            model_response = step.get('model_response', {})\n",
    "            tool_calls = model_response.get('tool_calls', [])\n",
    "            for tool_call in tool_calls:\n",
    "                tool_name = tool_call.get('tool_name', '')\n",
    "                if tool_name and tool_name not in tools_used:\n",
    "                    tools_used.append(tool_name)\n",
    "    \n",
    "    return tools_used\n",
    "\n",
    "def extract_response_text(data):\n",
    "    \"\"\"Extract response text from messages or steps\"\"\"\n",
    "    messages = data.get('messages', [])\n",
    "    steps = data.get('steps', [])\n",
    "    response_text = None\n",
    "    \n",
    "    # Try messages first\n",
    "    for msg in reversed(messages):\n",
    "        if msg.get('role') == 'assistant':\n",
    "            content = msg.get('content', '')\n",
    "            if isinstance(content, str) and content.strip():\n",
    "                response_text = content\n",
    "                break\n",
    "            elif isinstance(content, list) and content:\n",
    "                for item in content:\n",
    "                    if isinstance(item, dict):\n",
    "                        text = item.get('text', '')\n",
    "                        if text:\n",
    "                            response_text = text\n",
    "                            break\n",
    "                    elif isinstance(item, str) and item.strip():\n",
    "                        response_text = item\n",
    "                        break\n",
    "                if response_text:\n",
    "                    break\n",
    "    \n",
    "    # If not found in messages, check steps\n",
    "    if not response_text:\n",
    "        for step in reversed(steps):\n",
    "            if step.get('type') == 'inference' or step.get('step_type') == 'inference':\n",
    "                model_response = step.get('model_response', {})\n",
    "                content = model_response.get('content', '')\n",
    "                if isinstance(content, str) and content.strip():\n",
    "                    response_text = content\n",
    "                    break\n",
    "    \n",
    "    return response_text\n",
    "\n",
    "def retrieve_turn_with_retry(llamastack_url, agent_id, session_id, turn_id, max_retries=5, initial_wait=2):\n",
    "    \"\"\"Retrieve turn with retry logic\"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        wait_time = initial_wait * (2 ** attempt)  # Exponential backoff\n",
    "        if attempt > 0:\n",
    "            print(f\"   ‚è≥ Retry {attempt}/{max_retries-1} (waiting {wait_time}s)...\")\n",
    "            time.sleep(wait_time)\n",
    "        else:\n",
    "            time.sleep(wait_time)\n",
    "        \n",
    "        try:\n",
    "            response = httpx.get(\n",
    "                f\"{llamastack_url}/v1alpha/agents/{agent_id}/session/{session_id}/turn/{turn_id}\",\n",
    "                verify=False,\n",
    "                timeout=30\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            if response.text and response.text.strip() != 'null':\n",
    "                data = response.json()\n",
    "                steps = data.get('steps', [])\n",
    "                \n",
    "                # Check if turn is complete (has final inference step with content)\n",
    "                is_complete = False\n",
    "                for step in reversed(steps):\n",
    "                    if step.get('type') == 'inference' or step.get('step_type') == 'inference':\n",
    "                        model_response = step.get('model_response', {})\n",
    "                        content = model_response.get('content', '')\n",
    "                        if content and content.strip():\n",
    "                            is_complete = True\n",
    "                            break\n",
    "                \n",
    "                if is_complete or len(steps) > 0:\n",
    "                    return data\n",
    "                elif attempt < max_retries - 1:\n",
    "                    continue  # Try again\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt < max_retries - 1:\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    return None\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Testing Multiple Queries\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_queries = [\n",
    "    \"What collections are in the mcp_demo database?\",\n",
    "    \"How many documents are in the mcp_demo.incidents collection?\",\n",
    "    \"Show me one document from the mcp_demo.incidents collection\",\n",
    "]\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Test {i}: {query}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    try:\n",
    "        # Create turn\n",
    "        print(\"   üì§ Creating turn...\")\n",
    "        turn_stream = client.alpha.agents.turn.create(\n",
    "            agent_id=agent.agent_id,\n",
    "            session_id=session.session_id,\n",
    "            messages=[{\"role\": \"user\", \"content\": query}],\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        # Get turn_id\n",
    "        print(\"   üîç Extracting turn_id...\")\n",
    "        turn_id = None\n",
    "        for chunk in turn_stream:\n",
    "            if hasattr(chunk, 'event') and chunk.event and hasattr(chunk.event, 'payload'):\n",
    "                payload = chunk.event.payload\n",
    "                d = to_dict(payload)\n",
    "                turn_id = d.get('turn_id')\n",
    "                if not turn_id and 'step_details' in d:\n",
    "                    step_details = to_dict(d['step_details'])\n",
    "                    turn_id = step_details.get('turn_id')\n",
    "                if turn_id:\n",
    "                    break\n",
    "        \n",
    "        if turn_id:\n",
    "            print(f\"   ‚úÖ Turn ID: {turn_id}\")\n",
    "            print(\"   ‚è≥ Retrieving turn results...\")\n",
    "            \n",
    "            # Retrieve with retry\n",
    "            data = retrieve_turn_with_retry(\n",
    "                llamastack_url, \n",
    "                agent.agent_id, \n",
    "                session.session_id, \n",
    "                turn_id\n",
    "            )\n",
    "            \n",
    "            if data:\n",
    "                steps = data.get('steps', [])\n",
    "                messages = data.get('messages', [])\n",
    "                \n",
    "                # Extract tools used\n",
    "                tools_used = extract_tools_from_steps(steps)\n",
    "                \n",
    "                # Extract response\n",
    "                response_text = extract_response_text(data)\n",
    "                \n",
    "                # Display results\n",
    "                print(f\"\\n   üìä Results:\")\n",
    "                print(f\"      Steps: {len(steps)}\")\n",
    "                print(f\"      Messages: {len(messages)}\")\n",
    "                \n",
    "                if tools_used:\n",
    "                    print(f\"      üîß Tools used: {', '.join(tools_used)}\")\n",
    "                else:\n",
    "                    print(f\"      üîß Tools used: None\")\n",
    "                    # Show step types for debugging\n",
    "                    step_types = [step.get('type', '') or step.get('step_type', '') for step in steps]\n",
    "                    if step_types:\n",
    "                        print(f\"      üìã Step types: {', '.join(step_types)}\")\n",
    "                \n",
    "                if response_text:\n",
    "                    # Truncate long responses\n",
    "                    display_text = response_text[:300] + \"...\" if len(response_text) > 300 else response_text\n",
    "                    print(f\"      üí¨ Response: {display_text}\")\n",
    "                else:\n",
    "                    print(f\"      ‚ö†Ô∏è  No response text found\")\n",
    "                    # Try to show what we have\n",
    "                    if steps:\n",
    "                        print(f\"      üí° Check Part 5 and Part 6 for detailed step information\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è  Could not retrieve turn data after retries\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  Could not get turn_id from stream\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n‚úÖ Multiple query test complete!\")\n",
    "print(\"\\nüí° Tip: For detailed tool usage and step information, check Part 5 and Part 6 above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "**What we learned:**\n",
    "\n",
    "1. **MCP (Model Context Protocol)** provides a standardized protocol for tool integration - one protocol, many tools!\n",
    "2. **Agent Configuration** - Agents must be configured with toolgroups to access MCP tools\n",
    "3. **Automatic Tool Usage** - Agents automatically decide when to use tools based on queries\n",
    "4. **Turn-based Interaction** - Agents work through turns: create turn ‚Üí stream ‚Üí retrieve results\n",
    "5. **Tool Execution Flow** - Agents call tools, receive results, and generate responses using real data\n",
    "\n",
    "**The big picture:**\n",
    "- **MCP** standardizes tool integration - build tools once, use with any agent\n",
    "- **Agents** automatically use tools when needed - you don't need to explicitly call tools\n",
    "- **Tool execution** is transparent - you can see what tools were called and their results\n",
    "- **Real data** - Agents use actual data from MongoDB, not just training data\n",
    "\n",
    "**For IT operations:**\n",
    "- Build MCP tools for your monitoring systems, ticketing systems, databases\n",
    "- Give agents access to your infrastructure through MCP\n",
    "- Watch agents automatically use tools to answer questions\n",
    "- Create production-ready agents that can actually manage your systems\n",
    "\n",
    "**The workflow:**\n",
    "1. Create agent with MCP toolgroups\n",
    "2. Create session for conversation context\n",
    "3. Query agent (it automatically uses tools!)\n",
    "4. Retrieve turn results to see response and tool usage\n",
    "5. Analyze steps to understand what happened\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "**Ready for more?** In **Notebook 05**, we'll explore:\n",
    "- **Safety Shields** - Content moderation and safety checks (protect against harmful outputs)\n",
    "- **Content Moderation** - Checking inputs and outputs for safety violations\n",
    "- **Production-ready safety** - Building agents that are safe to deploy\n",
    "\n",
    "**The fun part:** You'll learn how to protect your agents from harmful inputs and outputs - essential for production deployment!\n",
    "\n",
    "---\n",
    "\n",
    "**Ready?** Let's move to Notebook 05: Safety Shields! üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
