{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02: Building a Simple Agent with Tools\n",
    "\n",
    "## üéØ What is This Notebook About?\n",
    "\n",
    "In this notebook, we'll build autonomous agents with tools using LlamaStack. We'll start with a custom Wikipedia search tool and then build more complex custom tools.\n",
    "\n",
    "**What we'll learn:**\n",
    "1. How to create a custom Wikipedia search tool\n",
    "2. How to create sessions and execute turns\n",
    "3. How to see tool calls using AgentEventLogger\n",
    "4. How to create custom (client-side) tools\n",
    "5. How to use custom tools with agents\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Prerequisites\n",
    "\n",
    "- LlamaStack server running (see Module README)\n",
    "- Python environment with dependencies installed\n",
    "- `requests` library (for Wikipedia API calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from llama_stack_client import LlamaStackClient, AgentEventLogger\n",
    "from termcolor import cprint\n",
    "\n",
    "# ============================================================================\n",
    "# Configuration - Update these values for your OpenShift deployment\n",
    "# ============================================================================\n",
    "\n",
    "# LlamaStack URL - Get from OpenShift route or set manually\n",
    "# Option 1: Use OpenShift route (external access)\n",
    "#   Get route URL: oc get route llamastack-route -n my-first-model -o jsonpath='{.spec.host}'\n",
    "#   Example: llamastack_url = \"https://llamastack-route-my-first-model.apps.ocp.example.com\"\n",
    "llamastack_url = os.getenv(\"LLAMA_STACK_URL\", \"https://llamastack-route-my-first-model.apps.ocp.5pndc.sandbox5432.opentlc.com\")\n",
    "\n",
    "# Option 2: Use service URL (if running inside cluster)\n",
    "#   llamastack_url = \"http://lsd-llama-milvus-inline-service.my-first-model.svc.cluster.local:8321\"\n",
    "\n",
    "# Option 3: Use localhost (if port-forwarding)\n",
    "#   llamastack_url = \"http://localhost:8321\"\n",
    "\n",
    "# Model identifier - Use the full identifier from LlamaStack\n",
    "model = os.getenv(\"LLAMA_MODEL\", \"vllm-inference/llama-32-3b-instruct\")\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"üì° LlamaStack URL: {llamastack_url}\")\n",
    "print(f\"ü§ñ Model: {model}\")\n",
    "\n",
    "# Initialize LlamaStack client\n",
    "client = LlamaStackClient(base_url=llamastack_url)\n",
    "\n",
    "# Verify connection\n",
    "try:\n",
    "    models = client.models.list()\n",
    "    model_count = len(models.data) if hasattr(models, 'data') else len(models)\n",
    "    print(f\"\\n‚úÖ Connected to LlamaStack\")\n",
    "    print(f\"   Available models: {model_count}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Cannot connect to LlamaStack: {e}\")\n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    print(\"   1. Check if route exists: oc get route llamastack-route -n my-first-model\")\n",
    "    print(\"   2. Update llamastack_url variable above with your route URL\")\n",
    "    print(\"   3. Or set LLAMA_STACK_URL environment variable:\")\n",
    "    print(\"      export LLAMA_STACK_URL='https://<route-host>'\")\n",
    "    print(\"   4. Or use service URL if running in cluster:\")\n",
    "    print(\"      llamastack_url = 'http://lsd-llama-milvus-inline-service.my-first-model.svc.cluster.local:8321'\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Create an Agent with Custom Wikipedia Search\n",
    "\n",
    "**What we're doing:** Creating a **custom Wikipedia search tool** and giving it to an agent.\n",
    "\n",
    "**Why:** Wikipedia is perfect for learning because:\n",
    "- ‚úÖ No API key required (free and easy!)\n",
    "- ‚úÖ Runs client-side (in your Python process - no external dependencies)\n",
    "- ‚úÖ Shows how to create custom tools (the pattern you'll use for everything)\n",
    "- ‚úÖ Perfect for factual information and general knowledge\n",
    "\n",
    "**The fun part:** We'll create a `wikipedia_search` function and pass it to the agent. The agent will automatically detect it as a tool based on the function's docstring! No complex configuration needed - just write a function with a good docstring, and the agent figures it out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a custom Wikipedia search tool\n",
    "# Wikipedia doesn't require an API key - perfect for learning!\n",
    "print(\"=\" * 60)\n",
    "print(\"Creating Custom Wikipedia Search Tool\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Import requests for API calls\n",
    "import requests\n",
    "import inspect\n",
    "import json\n",
    "import re\n",
    "\n",
    "def wikipedia_search(query: str, max_results: int = 3) -> str:\n",
    "    \"\"\"\n",
    "    Search Wikipedia for information.\n",
    "    \n",
    "    This tool searches Wikipedia for factual information. Use it when you need\n",
    "    general knowledge, definitions, or information about well-known topics.\n",
    "    \n",
    "    :param query: The search query to look up (e.g., \"Python programming\", \"Artificial Intelligence\")\n",
    "    :param max_results: Maximum number of results to return (default: 3)\n",
    "    :return: A formatted string with Wikipedia search results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "        \n",
    "        # First, try the search API (more flexible for general queries)\n",
    "        search_url = \"https://en.wikipedia.org/api/rest_v1/page/search\"\n",
    "        params = {\"q\": query, \"limit\": max_results}\n",
    "        search_response = requests.get(search_url, params=params, timeout=5)\n",
    "        \n",
    "        if search_response.status_code == 200:\n",
    "            results = search_response.json().get(\"pages\", [])\n",
    "            if results:\n",
    "                formatted = f\"Wikipedia search results for '{query}':\\n\\n\"\n",
    "                for j, page in enumerate(results[:max_results], 1):\n",
    "                    title = page.get(\"title\", \"No title\")\n",
    "                    snippet = page.get(\"snippet\", \"No snippet\")\n",
    "                    # Try to get the full summary for the first result\n",
    "                    if j == 1:\n",
    "                        try:\n",
    "                            page_url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{title.replace(' ', '_')}\"\n",
    "                            page_response = requests.get(page_url, timeout=5)\n",
    "                            if page_response.status_code == 200:\n",
    "                                page_data = page_response.json()\n",
    "                                extract = page_data.get(\"extract\", snippet)\n",
    "                                formatted += f\"{j}. {title}\\n\"\n",
    "                                formatted += f\"   {extract[:400]}...\\n\\n\"\n",
    "                            else:\n",
    "                                formatted += f\"{j}. {title}\\n\"\n",
    "                                formatted += f\"   {snippet[:300]}...\\n\\n\"\n",
    "                        except:\n",
    "                            formatted += f\"{j}. {title}\\n\"\n",
    "                            formatted += f\"   {snippet[:300]}...\\n\\n\"\n",
    "                    else:\n",
    "                        formatted += f\"{j}. {title}\\n\"\n",
    "                        formatted += f\"   {snippet[:300]}...\\n\\n\"\n",
    "                return formatted.strip()\n",
    "        \n",
    "        # Fallback: try direct page access\n",
    "        page_url = \"https://en.wikipedia.org/api/rest_v1/page/summary/\" + query.replace(\" \", \"_\")\n",
    "        response = requests.get(page_url, timeout=5)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            title = data.get(\"title\", query)\n",
    "            extract = data.get(\"extract\", \"No summary available\")\n",
    "            page_url_desktop = data.get(\"content_urls\", {}).get(\"desktop\", {}).get(\"page\", \"\")\n",
    "            \n",
    "            result = f\"Wikipedia: {title}\\n\"\n",
    "            result += f\"URL: {page_url_desktop}\\n\"\n",
    "            result += f\"Summary: {extract[:500]}...\\n\"\n",
    "            return result\n",
    "            \n",
    "        return f\"No Wikipedia results found for: {query}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error searching Wikipedia: {str(e)}\"\n",
    "\n",
    "# Helper function to parse JSON tool calls from response\n",
    "def parse_tool_call(content):\n",
    "    \"\"\"Parse JSON tool call from model response.\"\"\"\n",
    "    content = content.strip()\n",
    "    \n",
    "    # Try to find JSON object\n",
    "    json_match = re.search(r'\\{[^{}]*\"tool_call\"[^{}]*\\}', content)\n",
    "    if not json_match:\n",
    "        # Try broader match for nested objects\n",
    "        brace_count = 0\n",
    "        start_idx = content.find('{')\n",
    "        if start_idx != -1:\n",
    "            for i in range(start_idx, len(content)):\n",
    "                if content[i] == '{':\n",
    "                    brace_count += 1\n",
    "                elif content[i] == '}':\n",
    "                    brace_count -= 1\n",
    "                    if brace_count == 0:\n",
    "                        json_str = content[start_idx:i+1]\n",
    "                        try:\n",
    "                            return json.loads(json_str)\n",
    "                        except:\n",
    "                            pass\n",
    "    \n",
    "    if json_match:\n",
    "        try:\n",
    "            return json.loads(json_match.group())\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Store the function for client-side execution\n",
    "wikipedia_search_func = wikipedia_search\n",
    "tool_registry = {\"wikipedia_search\": wikipedia_search_func}\n",
    "\n",
    "# Create system prompt describing the tool\n",
    "wikipedia_tool_description = \"\"\"- wikipedia_search(query: str, max_results: int = 3): Search Wikipedia for information. \n",
    "  Use this tool when you need general knowledge, definitions, or information about well-known topics.\n",
    "  Parameters:\n",
    "    - query (string): The search query to look up (e.g., \"Python programming\", \"Artificial Intelligence\")\n",
    "    - max_results (integer): Maximum number of results to return (default: 3)\"\"\"\n",
    "\n",
    "system_prompt = f\"\"\"You are a helpful assistant with access to tools.\n",
    "\n",
    "When you need to use a tool, respond ONLY with valid JSON in this exact format:\n",
    "{{\n",
    "  \"tool_call\": \"function_name\",\n",
    "  \"arguments\": {{\"param1\": \"value1\", \"param2\": \"value2\"}}\n",
    "}}\n",
    "\n",
    "Available tools:\n",
    "{wikipedia_tool_description}\n",
    "\n",
    "IMPORTANT: \n",
    "- If you need to use a tool, respond with ONLY the JSON object, nothing else.\n",
    "- Do not include any text before or after the JSON.\n",
    "- Use the exact function name as shown above.\"\"\"\n",
    "\n",
    "print(\"\\n‚úÖ Custom wikipedia_search tool created!\")\n",
    "print(\"   Provider: Wikipedia (no API key required)\")\n",
    "print(\"   Function: wikipedia_search(query: str, max_results: int = 3)\")\n",
    "print(\"\\n‚úÖ System prompt created for prompt-based tool calling\")\n",
    "print(\"   Note: vLLM doesn't support the 'tools' parameter, so we use prompts instead\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create helper function for executing turns\n",
    "# This function handles tool detection and execution\n",
    "\n",
    "def execute_turn(task, messages, tool_registry, max_tokens=200):\n",
    "    \"\"\"\n",
    "    Execute a turn with the agent, detecting and executing tool calls.\n",
    "    \n",
    "    Returns True if a tool was used, False otherwise.\n",
    "    \"\"\"\n",
    "    print(f\"\\nüìã Task: {task}\")\n",
    "    print(f\"\\nüîÑ Agent execution (using prompt-based tool calling):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    cprint(f\"User> {task}\", \"green\")\n",
    "    \n",
    "    # Add user message to conversation\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": task,\n",
    "    })\n",
    "    \n",
    "    # Create chat completion with streaming\n",
    "    stream = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        stream=True,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0.1  # Lower temperature for more consistent JSON output\n",
    "    )\n",
    "    \n",
    "    # Process the stream\n",
    "    full_response = \"\"\n",
    "    print(\"\\nü§ñ Agent response:\")\n",
    "    print(\"-\" * 60)\n",
    "    for chunk in stream:\n",
    "        if chunk.choices and len(chunk.choices) > 0:\n",
    "            delta = chunk.choices[0].delta\n",
    "            if delta.content:\n",
    "                content = delta.content\n",
    "                print(content, end=\"\", flush=True)\n",
    "                full_response += content\n",
    "    \n",
    "    print(\"\\n\\n\" + \"-\" * 60)\n",
    "    \n",
    "    # Check if response contains a tool call\n",
    "    tool_call_data = parse_tool_call(full_response)\n",
    "    tool_calls_found = False\n",
    "    \n",
    "    if tool_call_data and \"tool_call\" in tool_call_data:\n",
    "        tool_calls_found = True\n",
    "        func_name = tool_call_data[\"tool_call\"]\n",
    "        func_args = tool_call_data.get(\"arguments\", {})\n",
    "        \n",
    "        print(f\"\\nüîß Tool call detected: {func_name}\")\n",
    "        print(f\"   Arguments: {func_args}\")\n",
    "        \n",
    "        # Execute the tool\n",
    "        if func_name in tool_registry:\n",
    "            print(f\"\\n   ‚Üí Executing {func_name}...\")\n",
    "            try:\n",
    "                result = tool_registry[func_name](**func_args)\n",
    "                print(f\"   ‚úÖ Tool result received ({len(result)} chars)\")\n",
    "                \n",
    "                # Add assistant message with tool call\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": full_response\n",
    "                })\n",
    "                \n",
    "                # Add tool result to conversation\n",
    "                messages.append({\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"Tool result: {result}. Now provide a natural language response based on this information.\"\n",
    "                })\n",
    "                \n",
    "                # Get final response with tool results\n",
    "                print(\"\\nü§ñ Final response with tool results:\")\n",
    "                print(\"-\" * 60)\n",
    "                final_response = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    stream=True,\n",
    "                    max_tokens=300\n",
    "                )\n",
    "                \n",
    "                final_text = \"\"\n",
    "                for chunk in final_response:\n",
    "                    if chunk.choices and len(chunk.choices) > 0:\n",
    "                        delta = chunk.choices[0].delta\n",
    "                        if delta.content:\n",
    "                            content = delta.content\n",
    "                            print(content, end=\"\", flush=True)\n",
    "                            final_text += content\n",
    "                \n",
    "                # Add final assistant response to messages\n",
    "                messages.append({\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": final_text\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error executing tool: {e}\")\n",
    "                tool_calls_found = False\n",
    "        else:\n",
    "            print(f\"   ‚ö†Ô∏è  Tool '{func_name}' not found in registry\")\n",
    "            tool_calls_found = False\n",
    "    else:\n",
    "        # No tool call detected - model answered directly\n",
    "        messages.append({\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": full_response\n",
    "        })\n",
    "        print(\"\\nüí° Model responded directly without using tools\")\n",
    "    \n",
    "    print(f\"\\n\\n{'=' * 60}\")\n",
    "    if tool_calls_found:\n",
    "        print(\"‚úÖ Turn completed! (Tools were used)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Turn completed, but no tool calls detected\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    \n",
    "    return tool_calls_found\n",
    "\n",
    "# Step 3: Initialize conversation\n",
    "# We'll use a messages list to maintain conversation context\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Initializing Conversation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialize messages list with system prompt\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt}\n",
    "]\n",
    "\n",
    "print(\"\\n‚úÖ Conversation initialized!\")\n",
    "print(\"\\nüí° We'll use a messages list to maintain conversation history and context.\")\n",
    "print(\"   The system prompt describes available tools and how to use them.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Execute a turn (give the agent a task)\n",
    "# A turn is one interaction with the agent\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Executing Turn with Task\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "task = \"What is Python programming? Use wikipedia_search to find information.\"\n",
    "\n",
    "# Use the execute_turn helper function\n",
    "tool_used = execute_turn(task, messages, tool_registry)\n",
    "\n",
    "# Inspect the turn - check if tools were called\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Inspecting Turn Response\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n‚úÖ Turn completed!\")\n",
    "print(\"\\nüí° Tip: Look for these indicators in the output above:\")\n",
    "print(\"   üîß = Tool call detected\")\n",
    "print(\"   ‚Üí = Tool being executed\")\n",
    "print(\"   ‚úÖ = Tool result received\")\n",
    "print(\"\\nIf you see üîß, the tool was used successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Create Custom IT Operations Tools\n",
    "\n",
    "**What we're doing:** Creating **custom IT operations tools** - Python functions that agents can use to manage infrastructure.\n",
    "\n",
    "**Why:** This is where it gets real! We'll build tools that check service status, restart services, and get system overviews - the kind of tools you'd use in production.\n",
    "\n",
    "**Key Points:**\n",
    "- Custom tools are Python functions with **docstrings** (the docstring is critical - the LLM reads it!)\n",
    "- Docstrings describe the tool to the LLM (what it does, when to use it, what parameters it needs)\n",
    "- Tools are passed directly to the Agent (no complex configuration)\n",
    "- Agent automatically detects and uses them (based on the docstring - magic!)\n",
    "\n",
    "**The fun part:** You'll see the agent reason about which tool to use. It might check status first, then decide to restart a service if needed. Watch it think!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a simple simulated IT environment\n",
    "class SimpleITEnvironment:\n",
    "    \"\"\"Simple simulated IT environment for our custom tools.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.services = {\n",
    "            \"web-server\": {\"status\": \"online\", \"cpu\": 45, \"memory\": 60},\n",
    "            \"database\": {\"status\": \"online\", \"cpu\": 30, \"memory\": 50},\n",
    "            \"cache-service\": {\"status\": \"degraded\", \"cpu\": 85, \"memory\": 90},\n",
    "        }\n",
    "    \n",
    "    def get_service_status(self, service_name: str) -> dict:\n",
    "        \"\"\"Get service status.\"\"\"\n",
    "        return self.services.get(service_name, {\"status\": \"not_found\"})\n",
    "    \n",
    "    def restart_service(self, service_name: str) -> str:\n",
    "        \"\"\"Restart a service.\"\"\"\n",
    "        if service_name in self.services:\n",
    "            self.services[service_name][\"status\"] = \"online\"\n",
    "            self.services[service_name][\"cpu\"] = 20\n",
    "            self.services[service_name][\"memory\"] = 30\n",
    "            return f\"Service {service_name} restarted successfully\"\n",
    "        return f\"Service {service_name} not found\"\n",
    "\n",
    "\n",
    "# Initialize environment\n",
    "env = SimpleITEnvironment()\n",
    "print(\"‚úÖ Created simulated IT environment\")\n",
    "print(f\"   Services: {list(env.services.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define custom tools as Python functions with docstrings\n",
    "# The docstrings are CRITICAL - the LLM uses them to understand the tools!\n",
    "\n",
    "def check_service_status(service_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Check the status of an IT service.\n",
    "    \n",
    "    Returns information about service health including CPU usage, memory usage, and current status.\n",
    "    Use this to monitor service health and detect issues.\n",
    "    \n",
    "    :param service_name: The name of the service to check (e.g., 'web-server', 'database', 'cache-service')\n",
    "    :return: A string describing the service status, CPU usage, and memory usage\n",
    "    \"\"\"\n",
    "    status = env.get_service_status(service_name)\n",
    "    if status.get(\"status\") == \"not_found\":\n",
    "        return f\"Service '{service_name}' not found\"\n",
    "    \n",
    "    return (\n",
    "        f\"Service: {service_name}\\n\"\n",
    "        f\"Status: {status['status']}\\n\"\n",
    "        f\"CPU Usage: {status['cpu']}%\\n\"\n",
    "        f\"Memory Usage: {status['memory']}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "def restart_service(service_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Restart an IT service that is not working properly.\n",
    "    \n",
    "    Use this when a service has failed or is in a degraded state.\n",
    "    This will stop and start the service, which may cause brief downtime.\n",
    "    \n",
    "    :param service_name: The name of the service to restart (e.g., 'web-server', 'database')\n",
    "    :return: A string confirming the restart operation\n",
    "    \"\"\"\n",
    "    return env.restart_service(service_name)\n",
    "\n",
    "\n",
    "def get_all_services() -> str:\n",
    "    \"\"\"\n",
    "    Get the status of all services in the environment.\n",
    "    \n",
    "    Use this to get an overview of the entire system health.\n",
    "    Returns a list of all services with their current status and metrics.\n",
    "    \n",
    "    :return: A string listing all services and their status\n",
    "    \"\"\"\n",
    "    result = \"All Services Status:\\n\"\n",
    "    for name, status in env.services.items():\n",
    "        result += f\"\\n{name}:\\n\"\n",
    "        result += f\"  Status: {status['status']}\\n\"\n",
    "        result += f\"  CPU: {status['cpu']}%\\n\"\n",
    "        result += f\"  Memory: {status['memory']}%\\n\"\n",
    "    return result\n",
    "\n",
    "\n",
    "print(\"\\n‚úÖ Custom tools defined:\")\n",
    "print(\"   - check_service_status(service_name: str)\")\n",
    "print(\"   - restart_service(service_name: str)\")\n",
    "print(\"   - get_all_services()\")\n",
    "print(\"\\nüí° Key Points:\")\n",
    "print(\"   - Tools are Python functions with docstrings\")\n",
    "print(\"   - Docstrings describe what the tool does\")\n",
    "print(\"   - :param describes parameters\")\n",
    "print(\"   - The LLM reads these docstrings to understand when to use each tool\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: These functions use the 'env' variable defined in the previous cell.\")\n",
    "print(\"   Make sure to run the previous cell first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Prepare custom tools for prompt-based calling\n",
    "# Bind the environment to the tool functions\n",
    "\n",
    "# Create bound functions that include the environment\n",
    "def check_service_status_bound(service_name: str) -> str:\n",
    "    return check_service_status(service_name)\n",
    "\n",
    "def restart_service_bound(service_name: str) -> str:\n",
    "    return restart_service(service_name)\n",
    "\n",
    "def get_all_services_bound() -> str:\n",
    "    return get_all_services()\n",
    "\n",
    "# Store bound functions for client-side execution\n",
    "it_tool_registry = {\n",
    "    \"check_service_status\": check_service_status_bound,\n",
    "    \"restart_service\": restart_service_bound,\n",
    "    \"get_all_services\": get_all_services_bound,\n",
    "}\n",
    "\n",
    "# Create tool descriptions for system prompt\n",
    "it_tool_descriptions = \"\"\"\n",
    "- check_service_status(service_name: str): Check the status of an IT service. \n",
    "  Returns information about service health including CPU usage, memory usage, and current status.\n",
    "  Use this to monitor service health and detect issues.\n",
    "  Parameters:\n",
    "    - service_name (string): The name of the service to check (e.g., 'web-server', 'database', 'cache-service')\n",
    "\n",
    "- restart_service(service_name: str): Restart an IT service that is not working properly.\n",
    "  Use this when a service has failed or is in a degraded state.\n",
    "  Parameters:\n",
    "    - service_name (string): The name of the service to restart (e.g., 'web-server', 'database')\n",
    "\n",
    "- get_all_services(): Get the status of all services in the environment.\n",
    "  Use this to get an overview of the entire system health.\n",
    "  No parameters required.\"\"\"\n",
    "\n",
    "it_system_prompt = f\"\"\"You are an IT operations agent with access to tools.\n",
    "\n",
    "When you need to use a tool, respond ONLY with valid JSON in this exact format:\n",
    "{{\n",
    "  \"tool_call\": \"function_name\",\n",
    "  \"arguments\": {{\"param1\": \"value1\"}}\n",
    "}}\n",
    "\n",
    "Available tools:\n",
    "{it_tool_descriptions}\n",
    "\n",
    "IMPORTANT: \n",
    "- If you need to use a tool, respond with ONLY the JSON object, nothing else.\n",
    "- Do not include any text before or after the JSON.\n",
    "- Use the exact function name as shown above.\n",
    "- Always check service status before taking actions.\n",
    "- Provide clear summaries of what you did.\"\"\"\n",
    "\n",
    "print(\"‚úÖ IT operations tools prepared\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Test the agent with custom tools\n",
    "# Initialize messages for IT operations conversation\n",
    "it_messages = [{\"role\": \"system\", \"content\": it_system_prompt}]\n",
    "\n",
    "# Test tasks\n",
    "test_tasks = [\n",
    "    \"Check the status of all services\",\n",
    "    \"Check the status of cache-service and restart it if it's degraded\",\n",
    "]\n",
    "\n",
    "print(\"\\nüìù Testing IT Operations Agent\\n\")\n",
    "\n",
    "for task in test_tasks:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Task: {task}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Execute turn using helper function\n",
    "    tool_used = execute_turn(task, it_messages, it_tool_registry, max_tokens=300)\n",
    "    \n",
    "    if tool_used:\n",
    "        print(\"\\n‚úÖ Tool was used\")\n",
    "    else:\n",
    "        print(\"\\nüí° No tool call detected\")\n",
    "        print(\"   The model may have answered directly, or tool call format was different\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ All tests completed!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéì Key Takeaways\n",
    "\n",
    "**What we learned:**\n",
    "\n",
    "1. **Custom Tools** are Python functions with docstrings - the agent detects them automatically (no complex configuration!)\n",
    "2. **Wikipedia Search** is a great example - free, no API key, perfect for learning the pattern\n",
    "3. **Agent Class** simplifies agent creation and tool management - just pass functions and go!\n",
    "4. **AgentEventLogger** shows tool calls visually - watch the agent think (ü§î) and act (üîß) in real-time\n",
    "5. **Sessions** maintain conversation context - agents remember what happened before\n",
    "\n",
    "**The big picture:**\n",
    "- Tools are the agent's \"hands\" - they let agents take actions, not just think\n",
    "- Docstrings are critical - the LLM reads them to understand when to use each tool\n",
    "- Client-side tools run in your Python process - fast, secure, no external dependencies\n",
    "- You can build any tool you need - Wikipedia, IT operations, databases, APIs, anything!\n",
    "\n",
    "**For IT operations:**\n",
    "- Build tools for your specific infrastructure (monitoring systems, service management, etc.)\n",
    "- Watch agents reason about problems and choose the right tools\n",
    "- See agents execute multi-step operations (check status ‚Üí detect problem ‚Üí fix it)\n",
    "- Create production-ready agents that can actually manage your systems\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "**Ready for more?** In **Notebook 03**, we'll explore:\n",
    "- **LlamaStack Core Features** - Chat and RAG (Retrieval Augmented Generation)\n",
    "- **When to use each feature** - Understanding which tool fits which problem\n",
    "- **Building more powerful agents** - Combining features for better results\n",
    "\n",
    "**The fun part:** You'll learn how to give agents access to knowledge bases (RAG) so they can answer questions about your specific infrastructure!\n",
    "\n",
    "---\n",
    "\n",
    "**Ready?** Let's move to Notebook 03: LlamaStack Core Features! üöÄ\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
