{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: LlamaStack Core Features\n",
    "\n",
    "## üéØ What is This Notebook About?\n",
    "\n",
    "Welcome! This notebook introduces you to the **core features of LlamaStack** that make powerful autonomous agents possible.\n",
    "\n",
    "**What we'll learn:**\n",
    "1. **Simple Chat** - Basic LLM interactions\n",
    "2. **RAG (Retrieval Augmented Generation)** - Enhancing LLMs with external knowledge\n",
    "3. **MCP (Model Context Protocol)** - Integrating external tools and data sources\n",
    "4. **Safety** - Content moderation and safety shields\n",
    "5. **Evaluation** - Measuring and improving AI performance\n",
    "\n",
    "**Why this matters:**\n",
    "- Understanding these features helps you build better agents\n",
    "- Each feature solves specific problems\n",
    "- Combining them creates powerful autonomous systems\n",
    "- These are the building blocks for advanced agents\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- ‚úÖ Understand each LlamaStack core feature\n",
    "- ‚úÖ Know when to use each feature\n",
    "- ‚úÖ See practical examples of each feature\n",
    "- ‚úÖ Be ready to combine features in advanced agents\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è Setup\n",
    "\n",
    "Let's start by setting up our environment and connecting to LlamaStack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path for imports\n",
    "notebook_dir = Path().resolve()\n",
    "src_path = notebook_dir.parent / 'src'\n",
    "sys.path.insert(0, str(src_path))\n",
    "\n",
    "# Import LlamaStack SDK\n",
    "from llama_stack_client import LlamaStackClient\n",
    "\n",
    "# Configuration\n",
    "llamastack_url = os.getenv(\"LLAMA_STACK_URL\", \"http://localhost:8321\")\n",
    "model = os.getenv(\"LLAMA_MODEL\", \"ollama/llama3.2:3b\")\n",
    "\n",
    "print(f\"üì° LlamaStack URL: {llamastack_url}\")\n",
    "print(f\"ü§ñ Model: {model}\")\n",
    "\n",
    "# Initialize client\n",
    "client = LlamaStackClient(base_url=llamastack_url)\n",
    "\n",
    "# Verify connection\n",
    "try:\n",
    "    models = client.models.list()\n",
    "    print(f\"‚úÖ Connected to LlamaStack\")\n",
    "    print(f\"   Available models: {len(models)}\")\n",
    "    if models:\n",
    "        print(f\"   Using model: {model}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cannot connect to LlamaStack: {e}\")\n",
    "    print(\"   Please ensure LlamaStack is running:\")\n",
    "    print(\"   python scripts/start_llama_stack.py\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Simple Chat\n",
    "\n",
    "### What is Chat?\n",
    "\n",
    "**Chat completion** is the most basic way to interact with an LLM. You send messages and get responses.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Messages** have roles: `system`, `user`, `assistant`\n",
    "- **System messages** set the AI's behavior and personality\n",
    "- **User messages** are your questions or requests\n",
    "- **Assistant messages** are the AI's responses (in conversation history)\n",
    "\n",
    "**Use Cases:**\n",
    "- Simple Q&A\n",
    "- Conversational interfaces\n",
    "- Text generation\n",
    "- Basic reasoning tasks\n",
    "\n",
    "Let's see it in action!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Basic Chat Completion\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Basic Chat\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful IT operations assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France? Answer in one sentence.\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Chat response received!\")\n",
    "if hasattr(response, 'choices') and response.choices:\n",
    "    content = response.choices[0].message.content\n",
    "    print(f\"\\nResponse: {content}\")\n",
    "else:\n",
    "    print(f\"Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Multi-turn Conversation\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 2: Multi-turn Conversation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# First turn\n",
    "response1 = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"My name is Alice. What's my name?\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Turn 1:\")\n",
    "if response1.choices:\n",
    "    print(f\"  User: My name is Alice. What's my name?\")\n",
    "    print(f\"  Assistant: {response1.choices[0].message.content}\")\n",
    "\n",
    "# Second turn (with conversation history)\n",
    "response2 = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"My name is Alice. What's my name?\"},\n",
    "        {\"role\": \"assistant\", \"content\": response1.choices[0].message.content},\n",
    "        {\"role\": \"user\", \"content\": \"What did I just tell you my name was?\"}\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"\\nTurn 2:\")\n",
    "if response2.choices:\n",
    "    print(f\"  User: What did I just tell you my name was?\")\n",
    "    print(f\"  Assistant: {response2.choices[0].message.content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Streaming Response\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 3: Streaming Response\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"Question: Explain what an autonomous agent is in 2-3 sentences.\\n\")\n",
    "print(\"Streaming response:\")\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful AI educator.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Explain what an autonomous agent is in 2-3 sentences.\"}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "full_response = \"\"\n",
    "for chunk in stream:\n",
    "    if chunk.choices and chunk.choices[0].delta.content:\n",
    "        content = chunk.choices[0].delta.content\n",
    "        print(content, end=\"\", flush=True)\n",
    "        full_response += content\n",
    "\n",
    "print(\"\\n\\n‚úÖ Streaming complete!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: RAG (Retrieval Augmented Generation)\n",
    "\n",
    "### What is RAG?\n",
    "\n",
    "**RAG** enhances LLMs by giving them access to external knowledge through **vector stores**.\n",
    "\n",
    "**How it works:**\n",
    "1. **Store documents** in a vector store (documents are converted to embeddings)\n",
    "2. **Search** for relevant documents when needed\n",
    "3. **Retrieve** context from documents\n",
    "4. **Augment** the LLM prompt with retrieved context\n",
    "5. **Generate** response using both LLM knowledge and retrieved context\n",
    "\n",
    "**Use Cases:**\n",
    "- Answering questions about specific documents\n",
    "- Knowledge bases and documentation\n",
    "- Domain-specific information\n",
    "- Up-to-date information not in training data\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Vector Store**: Database of document embeddings\n",
    "- **Embeddings**: Numerical representations of text\n",
    "- **Retrieval**: Finding relevant documents\n",
    "- **Context**: Retrieved information added to prompts\n",
    "\n",
    "Let's explore RAG!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Check Vector Stores\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Exploring Vector Stores\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# List existing vector stores\n",
    "vector_stores = client.vector_stores.list()\n",
    "store_count = len(vector_stores) if hasattr(vector_stores, '__len__') else 0\n",
    "print(f\"Found {store_count} existing vector stores\")\n",
    "\n",
    "# Show available methods\n",
    "print(f\"\\nAvailable vector store operations:\")\n",
    "print(f\"  - create: Create a new vector store\")\n",
    "print(f\"  - list: List all vector stores\")\n",
    "print(f\"  - search: Search for relevant documents\")\n",
    "print(f\"  - files: Manage files in vector stores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Create a Vector Store (if supported)\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 2: Creating a Vector Store\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Create a test vector store\n",
    "    vs_response = client.vector_stores.create(\n",
    "        name=\"test-rag-store\",\n",
    "        description=\"Test vector store for RAG demonstration\"\n",
    "    )\n",
    "    \n",
    "    store_id = vs_response.id if hasattr(vs_response, 'id') else 'created'\n",
    "    print(f\"‚úÖ Created vector store: {store_id}\")\n",
    "    \n",
    "    print(\"\\nüìù To use RAG:\")\n",
    "    print(\"  1. Add files: client.vector_stores.files.create(vector_store_id=store_id, ...)\")\n",
    "    print(\"  2. Search: client.vector_stores.search(vector_store_id=store_id, query='...')\")\n",
    "    print(\"  3. Use retrieved context in chat completion\")\n",
    "    \n",
    "    # Clean up\n",
    "    if hasattr(vs_response, 'id'):\n",
    "        try:\n",
    "            client.vector_stores.delete(vs_response.id)\n",
    "            print(\"\\nüßπ Cleaned up test vector store\")\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"‚ÑπÔ∏è  Vector store creation: {e}\")\n",
    "    print(\"\\nüìù RAG Workflow:\")\n",
    "    print(\"  1. Create a vector store\")\n",
    "    print(\"  2. Add documents/files to the store\")\n",
    "    print(\"  3. Search for relevant documents\")\n",
    "    print(\"  4. Use retrieved context in chat completion\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: MCP (Model Context Protocol)\n",
    "\n",
    "### What is MCP?\n",
    "\n",
    "**MCP** allows agents to access external tools, data sources, and services.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Tool Runtime**: Execution environment for tools\n",
    "- **Tool Groups**: Collections of related tools\n",
    "- **Tool Execution**: Running tools and getting results\n",
    "- **External Integration**: Connecting to APIs, databases, services\n",
    "\n",
    "**Use Cases:**\n",
    "- API integrations\n",
    "- Database queries\n",
    "- External service calls\n",
    "- Custom tool execution\n",
    "\n",
    "**Why it matters:**\n",
    "- Agents can do more than just chat\n",
    "- Access real-world data and services\n",
    "- Extend agent capabilities\n",
    "- Enable autonomous actions\n",
    "\n",
    "Let's explore MCP!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Explore Tool Runtime\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Tool Runtime\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check tool runtime\n",
    "if hasattr(client, 'tool_runtime'):\n",
    "    print(\"‚úÖ Tool runtime available\")\n",
    "    print(f\"   Methods: {[x for x in dir(client.tool_runtime) if not x.startswith('_')]}\")\n",
    "    \n",
    "    # List available tools\n",
    "    try:\n",
    "        tools = client.tool_runtime.list_tools()\n",
    "        print(f\"\\n   Available tools: {len(tools) if hasattr(tools, '__len__') else 'N/A'}\")\n",
    "    except:\n",
    "        print(\"   ‚ÑπÔ∏è  Tools may need to be configured\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Tool runtime not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Tool Groups\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 2: Tool Groups\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check tool groups\n",
    "if hasattr(client, 'toolgroups'):\n",
    "    toolgroups = client.toolgroups.list()\n",
    "    group_count = len(toolgroups) if hasattr(toolgroups, '__len__') else 0\n",
    "    print(f\"Found {group_count} tool groups\")\n",
    "    \n",
    "    print(\"\\nüìù Tool groups organize related tools together\")\n",
    "    print(\"   - Tools can be grouped by functionality\")\n",
    "    print(\"   - Agents can access tools through tool groups\")\n",
    "    print(\"   - MCP enables external tool integration\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Tool groups not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Safety\n",
    "\n",
    "### What is Safety?\n",
    "\n",
    "**Safety** ensures AI systems behave responsibly and safely.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Safety Shields**: Filters that check content before/after generation\n",
    "- **Content Moderation**: Detecting harmful or inappropriate content\n",
    "- **Safety Policies**: Rules for what content is allowed\n",
    "- **Safe AI Practices**: Best practices for responsible AI\n",
    "\n",
    "**Use Cases:**\n",
    "- Filtering harmful content\n",
    "- Preventing inappropriate responses\n",
    "- Ensuring compliance\n",
    "- Protecting users\n",
    "\n",
    "**Why it matters:**\n",
    "- Essential for production systems\n",
    "- Protects users and organizations\n",
    "- Ensures responsible AI use\n",
    "- Required for many applications\n",
    "\n",
    "Let's explore Safety!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Safety API\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Safety Infrastructure\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if hasattr(client, 'safety'):\n",
    "    print(\"‚úÖ Safety API available\")\n",
    "    print(f\"   Methods: {[x for x in dir(client.safety) if not x.startswith('_')]}\")\n",
    "    \n",
    "    print(\"\\nüìù Safety Features:\")\n",
    "    print(\"  - Safety shields: Filter content\")\n",
    "    print(\"  - Content moderation: Check for harmful content\")\n",
    "    print(\"  - Safety policies: Define what's allowed\")\n",
    "    print(\"  - Integration: Safety built into chat completions\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Safety API not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Content Moderation (if shield configured)\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 2: Content Moderation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_text = \"This is a test message to check safety filters.\"\n",
    "\n",
    "if hasattr(client, 'moderations'):\n",
    "    try:\n",
    "        moderation = client.moderations.create(\n",
    "            input=test_text,\n",
    "            model=model\n",
    "        )\n",
    "        print(f\"‚úÖ Moderation check successful!\")\n",
    "        print(f\"   Input: {test_text}\")\n",
    "        if hasattr(moderation, 'results') and moderation.results:\n",
    "            result = moderation.results[0]\n",
    "            flagged = getattr(result, 'flagged', False)\n",
    "            print(f\"   Flagged: {flagged}\")\n",
    "            if flagged:\n",
    "                categories = getattr(result, 'categories', {})\n",
    "                print(f\"   Categories: {categories}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ÑπÔ∏è  Moderation requires shield configuration\")\n",
    "        print(f\"   Error: {e}\")\n",
    "        print(\"\\nüìù To use safety:\")\n",
    "        print(\"  1. Configure a safety shield for your model\")\n",
    "        print(\"  2. Use safety.run_shield() to check content\")\n",
    "        print(\"  3. Safety is often integrated into chat completions\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Moderation API available but requires configuration\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Evaluation\n",
    "\n",
    "### What is Evaluation?\n",
    "\n",
    "**Evaluation** measures how well your AI system performs.\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Evaluation Dataset**: Test cases with inputs and expected outputs\n",
    "- **Metrics**: Ways to measure performance (accuracy, BLEU, ROUGE, etc.)\n",
    "- **Evaluation Jobs**: Running evaluations on datasets\n",
    "- **Performance Tracking**: Monitoring improvements over time\n",
    "\n",
    "**Use Cases:**\n",
    "- Measuring model performance\n",
    "- Comparing different models\n",
    "- Tracking improvements\n",
    "- Quality assurance\n",
    "\n",
    "**Why it matters:**\n",
    "- Know if your system works well\n",
    "- Identify areas for improvement\n",
    "- Compare different approaches\n",
    "- Ensure quality\n",
    "\n",
    "Let's explore Evaluation!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Evaluation API\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 1: Evaluation Infrastructure\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if hasattr(client, 'alpha') and hasattr(client.alpha, 'eval'):\n",
    "    eval_api = client.alpha.eval\n",
    "    print(\"‚úÖ Evaluation API available\")\n",
    "    \n",
    "    eval_methods = [x for x in dir(eval_api) if not x.startswith('_') \n",
    "                    and x not in ['with_raw_response', 'with_streaming_response']]\n",
    "    print(f\"   Available methods: {eval_methods}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Evaluation API not available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Creating an Evaluation Dataset\n",
    "print(\"=\" * 60)\n",
    "print(\"Example 2: Evaluation Dataset\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a simple evaluation dataset\n",
    "test_data = [\n",
    "    {\n",
    "        \"input\": \"What is 2+2?\",\n",
    "        \"expected_output\": \"4\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is the capital of France?\",\n",
    "        \"expected_output\": \"Paris\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What color is the sky?\",\n",
    "        \"expected_output\": \"blue\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Created evaluation dataset with {len(test_data)} examples:\")\n",
    "for i, example in enumerate(test_data, 1):\n",
    "    print(f\"  {i}. Input: '{example['input']}' ‚Üí Expected: '{example['expected_output']}'\")\n",
    "\n",
    "print(\"\\nüìù To run evaluation:\")\n",
    "print(\"  eval_job = client.alpha.eval.run_eval_alpha(\")\n",
    "print(\"      dataset=test_data,\")\n",
    "print(f\"      model='{model}',\")\n",
    "print(\"      metrics=['accuracy', 'bleu'],\")\n",
    "print(\"  )\")\n",
    "print(\"\\nüìù Evaluation Metrics:\")\n",
    "print(\"  - accuracy: Correctness of responses\")\n",
    "print(\"  - bleu: Text similarity (for text generation)\")\n",
    "print(\"  - rouge: Text overlap (for summarization)\")\n",
    "print(\"  - custom: Your own metrics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "In this notebook, we explored five core LlamaStack features:\n",
    "\n",
    "1. **Simple Chat** - Basic LLM interactions with messages and streaming\n",
    "2. **RAG** - Enhancing LLMs with external knowledge through vector stores\n",
    "3. **MCP** - Integrating external tools and data sources\n",
    "4. **Safety** - Content moderation and safety shields\n",
    "5. **Evaluation** - Measuring and improving AI performance\n",
    "\n",
    "### When to Use Each Feature\n",
    "\n",
    "- **Chat**: Simple Q&A, conversations, basic tasks\n",
    "- **RAG**: When you need domain-specific or up-to-date knowledge\n",
    "- **MCP**: When you need to interact with external systems\n",
    "- **Safety**: Always in production, content filtering\n",
    "- **Evaluation**: Measuring performance, comparing models, quality assurance\n",
    "\n",
    "### How Features Work Together\n",
    "\n",
    "These features can be combined:\n",
    "- **Agent + RAG**: Knowledge-augmented agents\n",
    "- **Agent + MCP**: Agents with external tool access\n",
    "- **Agent + Safety**: Safe action-taking\n",
    "- **Agent + Eval**: Measured and improved performance\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In the next notebook, we'll see how to combine these features to build advanced autonomous agents!\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Key Takeaways\n",
    "\n",
    "‚úÖ Each feature solves specific problems  \n",
    "‚úÖ Features can be used independently or together  \n",
    "‚úÖ Understanding features helps build better agents  \n",
    "‚úÖ Safety and evaluation are essential for production  \n",
    "‚úÖ Next: Combining features in advanced agents\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
