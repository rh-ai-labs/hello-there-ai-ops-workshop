{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 01: Load and Explore Dataset\n",
    "\n",
    "## üéØ What is This Notebook About?\n",
    "\n",
    "Welcome! This is your first step in learning how AI can help improve IT incident documentation. Think of this notebook like a **guided tour** - we're going to open up a dataset (a collection of IT support tickets) and take a look around to understand what we're working with.\n",
    "\n",
    "**What we'll do:**\n",
    "1. **Load the data** - Get our IT incident tickets from an online repository\n",
    "2. **Take a look around** - See what information each ticket contains\n",
    "3. **Understand the data** - Learn about categories, types, and patterns\n",
    "4. **Check quality** - See which tickets have good documentation (close notes)\n",
    "5. **Prepare for next steps** - Get everything ready for the rest of the workshop\n",
    "\n",
    "**Why this matters:**\n",
    "- Before we can use AI to improve close notes, we need to understand what data we have\n",
    "- This is like checking your ingredients before cooking - you need to know what you're working with!\n",
    "- The better we understand the data, the better we can evaluate AI-generated improvements\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Key Concepts Explained\n",
    "\n",
    "### What is a Dataset?\n",
    "\n",
    "A **dataset** is simply a collection of data organized in a structured way. Think of it like a spreadsheet with rows (each row is one incident) and columns (each column is a piece of information about that incident).\n",
    "\n",
    "**Example:** Like a customer database with names, emails, and phone numbers - but here we have IT incidents with descriptions, categories, and resolution notes.\n",
    "\n",
    "### What is Hugging Face?\n",
    "\n",
    "**Hugging Face** is like a library or app store for AI datasets and models. Instead of creating our own data from scratch, we're using a pre-made dataset of IT support tickets that someone has already prepared and shared.\n",
    "\n",
    "**Think of it like:** Using a recipe book instead of inventing recipes - it saves time and gives us something proven to work with.\n",
    "\n",
    "### What are \"Close Notes\"?\n",
    "\n",
    "**Close notes** are the documentation that IT support agents write when they resolve an incident. They explain:\n",
    "- What the problem was\n",
    "- What they did to fix it\n",
    "- How they confirmed it was resolved\n",
    "\n",
    "**Why they matter:** Good close notes help other agents understand similar problems in the future. Bad close notes (like just saying \"Issue resolved\") don't help anyone.\n",
    "\n",
    "### What is \"Ground Truth\"?\n",
    "\n",
    "**Ground truth** means the \"correct\" or \"reference\" answer. In our case, these are the high-quality close notes that we'll use as examples of what \"good\" looks like.\n",
    "\n",
    "**Think of it like:** When learning to write, you look at examples of good essays. Here, we'll use good close notes as examples to compare against.\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Dataset Overview\n",
    "\n",
    "**Source:** [Hugging Face - KameronB/synthetic-it-callcenter-tickets](https://huggingface.co/datasets/KameronB/synthetic-it-callcenter-tickets)\n",
    "\n",
    "This dataset contains **synthetic** (artificially created but realistic) IT support tickets. They simulate real-world incidents and requests, which makes them perfect for learning and experimenting without using real customer data.\n",
    "\n",
    "**What's in each ticket?**\n",
    "- Incident number and date\n",
    "- Category (like SOFTWARE, NETWORK, EMAIL)\n",
    "- Description of the problem\n",
    "- Close notes (how it was resolved)\n",
    "- Quality scores (how informative the close notes are)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "# Think of these like tools in a toolbox - each one does a specific job\n",
    "\n",
    "import pandas as pd  # For working with data tables (like Excel spreadsheets)\n",
    "import numpy as np   # For doing math calculations\n",
    "import matplotlib.pyplot as plt  # For creating charts and graphs\n",
    "import seaborn as sns  # For making prettier charts\n",
    "from pathlib import Path  # For handling file paths\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# Add src directory to path so we can use our helper functions\n",
    "sys.path.append(str(Path(\"../src\").resolve()))\n",
    "\n",
    "# Import our custom helper functions\n",
    "# These are functions we created to make loading data easier\n",
    "from utils import load_incident_dataset, calculate_basic_stats\n",
    "\n",
    "# Set up plotting style (makes our charts look nicer)\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except OSError:\n",
    "    try:\n",
    "        plt.style.use('seaborn')\n",
    "    except OSError:\n",
    "        plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üìö Ready to start working with data!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset\n",
    "\n",
    "**What we're doing:** Loading our IT incident tickets from Hugging Face (an online repository).\n",
    "\n",
    "**Why:** We need the data before we can analyze it. Think of this like opening a file on your computer.\n",
    "\n",
    "**What to expect:** \n",
    "- The dataset might be large, so we'll load a sample (200 tickets) for faster experimentation\n",
    "- You'll see a message showing how many records were loaded\n",
    "- The data will be stored in a variable called `df` (short for \"dataframe\" - think of it as a spreadsheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "# We're loading 200 incidents as a sample (you can change this number if you want)\n",
    "# RANDOM_STATE = 42 ensures we get the same random sample each time (for consistency)\n",
    "\n",
    "SAMPLE_SIZE = 200  # Number of incidents to load (use None to load all)\n",
    "RANDOM_STATE = 42  # Random seed (keeps results consistent)\n",
    "\n",
    "# This function downloads and loads the data from Hugging Face\n",
    "df = load_incident_dataset(sample_size=SAMPLE_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "# Let's see what we got!\n",
    "print(f\"\\nüìä Dataset loaded successfully!\")\n",
    "print(f\"   Shape: {df.shape[0]} rows (incidents) √ó {df.shape[1]} columns (pieces of information)\")\n",
    "print(f\"\\nüìã Available columns (information fields):\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"   {i}. {col}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Dataset Overview\n",
    "\n",
    "**What we're doing:** Taking a first look at the data to see what it actually contains.\n",
    "\n",
    "**Why:** Before diving deep, we want to see:\n",
    "- What does a real incident look like?\n",
    "- What types of information do we have?\n",
    "- Are there any missing pieces of information?\n",
    "\n",
    "**Think of it like:** Opening a book and reading the first few pages to get a sense of what it's about.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "# This shows us what the actual data looks like - like looking at the first few rows of a spreadsheet\n",
    "\n",
    "print(\"üëÄ First 5 incidents in the dataset:\")\n",
    "print(\"=\"*80)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and missing values\n",
    "# This helps us understand:\n",
    "# - What kind of information is in each column (text, numbers, dates)?\n",
    "# - Are there any missing pieces of information?\n",
    "\n",
    "print(\"üìù Data Types:\")\n",
    "print(\"   (This tells us what kind of information each column contains)\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\n‚ùì Missing Values:\")\n",
    "print(\"   (This shows how many incidents are missing information in each column)\")\n",
    "print(\"   (0 means no missing data, higher numbers mean more missing data)\")\n",
    "missing = df.isnull().sum()\n",
    "print(missing[missing > 0])  # Only show columns with missing values\n",
    "if missing[missing > 0].empty:\n",
    "    print(\"   ‚úÖ No missing values!\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nüìä Dataset Summary Info:\")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Statistics\n",
    "\n",
    "**What we're doing:** Getting a summary of what's in our dataset - like a quick overview.\n",
    "\n",
    "**Why:** This gives us the \"big picture\" before we dive into details. It's like reading the summary on the back of a book.\n",
    "\n",
    "**What we'll learn:**\n",
    "- How many incidents vs requests we have\n",
    "- What categories are most common\n",
    "- How long it typically takes to resolve issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate basic statistics\n",
    "# This function counts things up and gives us summary numbers\n",
    "\n",
    "stats = calculate_basic_stats(df)\n",
    "\n",
    "print(\"üìä Dataset Statistics:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"üì¶ Total records: {stats['total_incidents']}\")\n",
    "print(f\"üö® Incidents: {stats['incidents']} (problems that need fixing)\")\n",
    "print(f\"üìã Requests: {stats['requests']} (requests for something new)\")\n",
    "if stats['avg_resolution_time']:\n",
    "    hours = stats['avg_resolution_time'] / 60\n",
    "    print(f\"‚è±Ô∏è  Average resolution time: {stats['avg_resolution_time']:.2f} minutes ({hours:.1f} hours)\")\n",
    "print(f\"\\nüè∑Ô∏è  Categories (types of problems):\")\n",
    "for category, count in stats['categories'].items():\n",
    "    percentage = (count / stats['total_incidents']) * 100\n",
    "    print(f\"   ‚Ä¢ {category}: {count} incidents ({percentage:.1f}%)\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizing the Data\n",
    "\n",
    "**What we're doing:** Creating charts and graphs to \"see\" patterns in our data.\n",
    "\n",
    "**Why:** Sometimes it's easier to understand data by looking at pictures rather than numbers. These visualizations help us see:\n",
    "- What types of problems are most common?\n",
    "- How do people usually contact support?\n",
    "- How long does it take to resolve issues?\n",
    "- What does the quality of close notes look like?\n",
    "\n",
    "**Think of it like:** Looking at a map instead of reading a list of addresses - the visual helps you understand patterns quickly.\n",
    "\n",
    "**What you'll see:**\n",
    "- Pie charts showing proportions (like \"what percentage are software issues?\")\n",
    "- Bar charts showing counts (like \"how many incidents per category?\")\n",
    "- Histograms showing distributions (like \"how long do most incidents take to resolve?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization dashboard\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.3)\n",
    "\n",
    "# 1. Category Distribution (Pie Chart)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "if 'category' in df.columns:\n",
    "    category_counts = df['category'].value_counts()\n",
    "    colors = sns.color_palette(\"husl\", len(category_counts))\n",
    "    wedges, texts, autotexts = ax1.pie(\n",
    "        category_counts.values, \n",
    "        labels=category_counts.index, \n",
    "        autopct='%1.1f%%',\n",
    "        colors=colors,\n",
    "        startangle=90\n",
    "    )\n",
    "    ax1.set_title('Incident Categories Distribution', fontsize=12, fontweight='bold')\n",
    "    # Improve text readability\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "\n",
    "# 2. Category Distribution (Bar Chart with counts)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "if 'category' in df.columns:\n",
    "    category_counts = df['category'].value_counts()\n",
    "    bars = ax2.bar(range(len(category_counts)), category_counts.values, color=colors)\n",
    "    ax2.set_xticks(range(len(category_counts)))\n",
    "    ax2.set_xticklabels(category_counts.index, rotation=45, ha='right')\n",
    "    ax2.set_ylabel('Count', fontsize=10)\n",
    "    ax2.set_title('Categories by Count', fontsize=12, fontweight='bold')\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Top 10 Subcategories\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "if 'subcategory' in df.columns:\n",
    "    subcat_counts = df['subcategory'].value_counts().head(10)\n",
    "    ax3.barh(range(len(subcat_counts)), subcat_counts.values, \n",
    "             color=sns.color_palette(\"viridis\", len(subcat_counts)))\n",
    "    ax3.set_yticks(range(len(subcat_counts)))\n",
    "    ax3.set_yticklabels(subcat_counts.index)\n",
    "    ax3.set_xlabel('Count', fontsize=10)\n",
    "    ax3.set_title('Top 10 Subcategories', fontsize=12, fontweight='bold')\n",
    "    ax3.grid(axis='x', alpha=0.3)\n",
    "    # Add value labels\n",
    "    for i, v in enumerate(subcat_counts.values):\n",
    "        ax3.text(v + 0.5, i, str(v), va='center', fontsize=9)\n",
    "\n",
    "# 4. Contact Type Distribution\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "if 'contact_type' in df.columns:\n",
    "    contact_counts = df['contact_type'].value_counts()\n",
    "    bars = ax4.bar(contact_counts.index, contact_counts.values, \n",
    "                   color=sns.color_palette(\"muted\", len(contact_counts)))\n",
    "    ax4.set_ylabel('Count', fontsize=10)\n",
    "    ax4.set_title('Contact Channel Distribution', fontsize=12, fontweight='bold')\n",
    "    ax4.grid(axis='y', alpha=0.3)\n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# 5. Type Distribution (Incident vs Request)\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "if 'type' in df.columns:\n",
    "    type_counts = df['type'].value_counts()\n",
    "    colors_type = sns.color_palette(\"Set2\", len(type_counts))\n",
    "    wedges, texts, autotexts = ax5.pie(\n",
    "        type_counts.values,\n",
    "        labels=type_counts.index,\n",
    "        autopct='%1.1f%%',\n",
    "        colors=colors_type,\n",
    "        startangle=90\n",
    "    )\n",
    "    ax5.set_title('Incident vs Request Distribution', fontsize=12, fontweight='bold')\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "\n",
    "# 6. Resolution Time Distribution\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "if 'resolution_time' in df.columns and df['resolution_time'].notna().any():\n",
    "    resolution_times = df['resolution_time'].dropna()\n",
    "    ax6.hist(resolution_times, bins=40, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax6.set_xlabel('Resolution Time (minutes)', fontsize=10)\n",
    "    ax6.set_ylabel('Frequency', fontsize=10)\n",
    "    ax6.set_title('Resolution Time Distribution', fontsize=12, fontweight='bold')\n",
    "    ax6.set_yscale('log')\n",
    "    ax6.grid(axis='y', alpha=0.3)\n",
    "    # Add statistics\n",
    "    ax6.axvline(resolution_times.median(), color='red', linestyle='--', \n",
    "                label=f'Median: {resolution_times.median():.1f} min')\n",
    "    ax6.axvline(resolution_times.mean(), color='orange', linestyle='--', \n",
    "                label=f'Mean: {resolution_times.mean():.1f} min')\n",
    "    ax6.legend(fontsize=8)\n",
    "\n",
    "# 7. Content Length Analysis\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "if 'content' in df.columns:\n",
    "    df['content_length'] = df['content'].astype(str).str.len()\n",
    "    ax7.hist(df['content_length'], bins=30, edgecolor='black', alpha=0.7, color='teal')\n",
    "    ax7.set_xlabel('Content Length (characters)', fontsize=10)\n",
    "    ax7.set_ylabel('Frequency', fontsize=10)\n",
    "    ax7.set_title('Incident Content Length Distribution', fontsize=12, fontweight='bold')\n",
    "    ax7.grid(axis='y', alpha=0.3)\n",
    "    ax7.axvline(df['content_length'].median(), color='red', linestyle='--', \n",
    "                label=f'Median: {df[\"content_length\"].median():.0f} chars')\n",
    "    ax7.legend(fontsize=8)\n",
    "\n",
    "# 8. Ground Truth Quality (Info Score)\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "if 'info_score_close_notes' in df.columns:\n",
    "    info_scores = df['info_score_close_notes'].dropna()\n",
    "    if len(info_scores) > 0:\n",
    "        ax8.hist(info_scores, bins=20, edgecolor='black', alpha=0.7, color='purple')\n",
    "        ax8.set_xlabel('Info Score', fontsize=10)\n",
    "        ax8.set_ylabel('Frequency', fontsize=10)\n",
    "        ax8.set_title('Ground Truth Quality Score\\n(close_notes info_score)', fontsize=12, fontweight='bold')\n",
    "        ax8.grid(axis='y', alpha=0.3)\n",
    "        ax8.axvline(info_scores.mean(), color='red', linestyle='--', \n",
    "                    label=f'Mean: {info_scores.mean():.2f}')\n",
    "        ax8.legend(fontsize=8)\n",
    "\n",
    "# 9. Reassignment Analysis\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "if 'reassigned_count' in df.columns:\n",
    "    reassign_counts = df['reassigned_count'].value_counts().sort_index()\n",
    "    bars = ax9.bar(reassign_counts.index, reassign_counts.values, \n",
    "                   color=sns.color_palette(\"rocket\", len(reassign_counts)))\n",
    "    ax9.set_xlabel('Number of Reassignments', fontsize=10)\n",
    "    ax9.set_ylabel('Count', fontsize=10)\n",
    "    ax9.set_title('Incident Reassignment Frequency', fontsize=12, fontweight='bold')\n",
    "    ax9.grid(axis='y', alpha=0.3)\n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax9.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{int(height)}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.suptitle('Dataset Overview Dashboard', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATASET SUMMARY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "if 'category' in df.columns:\n",
    "    print(f\"\\nüìä Categories: {df['category'].nunique()} unique categories\")\n",
    "    print(f\"   Most common: {df['category'].value_counts().index[0]} ({df['category'].value_counts().iloc[0]} incidents)\")\n",
    "if 'subcategory' in df.columns:\n",
    "    print(f\"\\nüìã Subcategories: {df['subcategory'].nunique()} unique subcategories\")\n",
    "    print(f\"   Most common: {df['subcategory'].value_counts().index[0]} ({df['subcategory'].value_counts().iloc[0]} incidents)\")\n",
    "if 'contact_type' in df.columns:\n",
    "    print(f\"\\nüìû Contact Channels: {df['contact_type'].nunique()} channels\")\n",
    "    print(f\"   Most used: {df['contact_type'].value_counts().index[0]} ({df['contact_type'].value_counts().iloc[0]} incidents)\")\n",
    "if 'resolution_time' in df.columns and df['resolution_time'].notna().any():\n",
    "    rt = df['resolution_time'].dropna()\n",
    "    print(f\"\\n‚è±Ô∏è  Resolution Time:\")\n",
    "    print(f\"   Mean: {rt.mean():.1f} minutes ({rt.mean()/60:.1f} hours)\")\n",
    "    print(f\"   Median: {rt.median():.1f} minutes ({rt.median()/60:.1f} hours)\")\n",
    "    print(f\"   Range: {rt.min():.1f} - {rt.max():.1f} minutes\")\n",
    "if 'reassigned_count' in df.columns:\n",
    "    print(f\"\\nüîÑ Reassignments:\")\n",
    "    print(f\"   Mean: {df['reassigned_count'].mean():.2f} reassignments per incident\")\n",
    "    print(f\"   Max: {df['reassigned_count'].max()} reassignments\")\n",
    "    no_reassign = (df['reassigned_count'] == 0).sum()\n",
    "    print(f\"   {no_reassign} incidents ({no_reassign/len(df)*100:.1f}%) had no reassignments\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Look at Real Examples\n",
    "\n",
    "**What we're doing:** Looking at actual incidents from the dataset to see what real data looks like.\n",
    "\n",
    "**Why:** Numbers and charts are great, but sometimes you need to see the actual text to understand what we're working with. This helps us understand:\n",
    "- What does a real incident description look like?\n",
    "- What do good close notes actually say?\n",
    "- How detailed are the problem descriptions?\n",
    "\n",
    "**Think of it like:** Reading a few example essays to understand what \"good writing\" looks like, rather than just seeing scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a sample incident in detail\n",
    "# This picks one random incident and shows us all its details\n",
    "\n",
    "sample_incident = df.sample(1).iloc[0]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üìã EXAMPLE INCIDENT - Let's see what real data looks like!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüî¢ Incident Number: {sample_incident.get('number', 'N/A')}\")\n",
    "print(f\"üìÖ Date: {sample_incident.get('date', 'N/A')}\")\n",
    "print(f\"üìû Contact Type: {sample_incident.get('contact_type', 'N/A')} (how the user contacted support)\")\n",
    "print(f\"üè∑Ô∏è  Category: {sample_incident.get('category', 'N/A')} (type of problem)\")\n",
    "print(f\"üè∑Ô∏è  Subcategory: {sample_incident.get('subcategory', 'N/A')} (more specific type)\")\n",
    "print(f\"üë§ Customer: {sample_incident.get('customer', 'N/A')}\")\n",
    "print(f\"\\nüìù Short Description:\")\n",
    "print(f\"   {sample_incident.get('short_description', 'N/A')}\")\n",
    "print(f\"\\nüìÑ Full Content (the problem description):\")\n",
    "print(f\"   {sample_incident.get('content', 'N/A')[:500]}...\")\n",
    "if 'close_notes' in sample_incident and pd.notna(sample_incident.get('close_notes')):\n",
    "    print(f\"\\n‚úÖ Close Notes (how it was resolved - this is what we want to improve!):\")\n",
    "    print(f\"   {sample_incident.get('close_notes', 'N/A')[:500]}...\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  No close notes available for this incident\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Content Quality Analysis\n",
    "\n",
    "**What we're doing:** Analyzing the quality and characteristics of the text in our incidents.\n",
    "\n",
    "**Why:** Before we can improve close notes with AI, we need to understand:\n",
    "- How long are the problem descriptions? (This affects how much context the AI has)\n",
    "- Do most incidents have close notes? (We need these as examples)\n",
    "- How detailed are the close notes compared to the problem descriptions?\n",
    "- What's the quality score of the close notes? (This tells us which ones are \"good\")\n",
    "\n",
    "**Key Questions:**\n",
    "- **Content length**: Are problem descriptions detailed enough for AI to understand?\n",
    "- **Ground truth availability**: Do we have enough examples of good close notes?\n",
    "- **Quality scores**: Which close notes are high-quality and can serve as references?\n",
    "\n",
    "**Think of it like:** Checking the quality of your ingredients before cooking - you want to know what you're working with!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive content analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Content Quality Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Calculate content metrics\n",
    "if 'content' in df.columns:\n",
    "    df['content_length'] = df['content'].astype(str).str.len()\n",
    "    df['content_word_count'] = df['content'].astype(str).str.split().str.len()\n",
    "    \n",
    "    # 1. Content Length Distribution\n",
    "    axes[0, 0].hist(df['content_length'], bins=30, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    axes[0, 0].axvline(df['content_length'].median(), color='red', linestyle='--', \n",
    "                       label=f'Median: {df[\"content_length\"].median():.0f} chars')\n",
    "    axes[0, 0].set_xlabel('Content Length (characters)', fontsize=10)\n",
    "    axes[0, 0].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[0, 0].set_title('Input Content Length Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "    axes[0, 0].legend(fontsize=9)\n",
    "    \n",
    "    # 2. Word Count Distribution\n",
    "    axes[0, 1].hist(df['content_word_count'], bins=30, edgecolor='black', alpha=0.7, color='teal')\n",
    "    axes[0, 1].axvline(df['content_word_count'].median(), color='red', linestyle='--', \n",
    "                       label=f'Median: {df[\"content_word_count\"].median():.0f} words')\n",
    "    axes[0, 1].set_xlabel('Word Count', fontsize=10)\n",
    "    axes[0, 1].set_ylabel('Frequency', fontsize=10)\n",
    "    axes[0, 1].set_title('Content Word Count Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "    axes[0, 1].legend(fontsize=9)\n",
    "    \n",
    "    # Check if close_notes exist (ground truth)\n",
    "    if 'close_notes' in df.columns:\n",
    "        has_close_notes = df['close_notes'].notna()\n",
    "        df_with_gt = df[has_close_notes].copy()\n",
    "        \n",
    "        if len(df_with_gt) > 0:\n",
    "            df_with_gt['close_notes_length'] = df_with_gt['close_notes'].astype(str).str.len()\n",
    "            df_with_gt['close_notes_word_count'] = df_with_gt['close_notes'].astype(str).str.split().str.len()\n",
    "            \n",
    "            # 3. Content vs Close Notes Length Comparison\n",
    "            axes[1, 0].scatter(df_with_gt['content_length'], df_with_gt['close_notes_length'], \n",
    "                              alpha=0.6, color='purple', s=50)\n",
    "            axes[1, 0].plot([0, max(df_with_gt['content_length'].max(), df_with_gt['close_notes_length'].max())],\n",
    "                            [0, max(df_with_gt['content_length'].max(), df_with_gt['close_notes_length'].max())],\n",
    "                            'r--', alpha=0.5, label='y=x line')\n",
    "            axes[1, 0].set_xlabel('Content Length (chars)', fontsize=10)\n",
    "            axes[1, 0].set_ylabel('Close Notes Length (chars)', fontsize=10)\n",
    "            axes[1, 0].set_title('Content vs Resolution Notes Length', fontsize=12, fontweight='bold')\n",
    "            axes[1, 0].grid(alpha=0.3)\n",
    "            axes[1, 0].legend(fontsize=9)\n",
    "            \n",
    "            # 4. Info Score Distribution\n",
    "            if 'info_score_close_notes' in df_with_gt.columns:\n",
    "                info_scores = df_with_gt['info_score_close_notes'].dropna()\n",
    "                if len(info_scores) > 0:\n",
    "                    axes[1, 1].hist(info_scores, bins=20, edgecolor='black', alpha=0.7, color='orange')\n",
    "                    axes[1, 1].axvline(info_scores.mean(), color='red', linestyle='--', \n",
    "                                      label=f'Mean: {info_scores.mean():.2f}')\n",
    "                    axes[1, 1].axvline(info_scores.median(), color='blue', linestyle='--', \n",
    "                                      label=f'Median: {info_scores.median():.2f}')\n",
    "                    axes[1, 1].set_xlabel('Info Score', fontsize=10)\n",
    "                    axes[1, 1].set_ylabel('Frequency', fontsize=10)\n",
    "                    axes[1, 1].set_title('Ground Truth Quality Score Distribution', fontsize=12, fontweight='bold')\n",
    "                    axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "                    axes[1, 1].legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print detailed statistics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CONTENT QUALITY STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "if 'content' in df.columns:\n",
    "    print(f\"\\nüìù Input Content (for LLM enrichment):\")\n",
    "    print(f\"   Average length: {df['content_length'].mean():.0f} characters\")\n",
    "    print(f\"   Median length: {df['content_length'].median():.0f} characters\")\n",
    "    print(f\"   Average word count: {df['content_word_count'].mean():.0f} words\")\n",
    "    print(f\"   Range: {df['content_length'].min()} - {df['content_length'].max()} characters\")\n",
    "    \n",
    "    if 'close_notes' in df.columns:\n",
    "        has_close_notes = df['close_notes'].notna().sum()\n",
    "        print(f\"\\n‚úÖ Ground Truth (close_notes) Availability:\")\n",
    "        print(f\"   Incidents with close_notes: {has_close_notes} ({has_close_notes/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        if has_close_notes > 0:\n",
    "            df_with_gt = df[df['close_notes'].notna()].copy()\n",
    "            df_with_gt['close_notes_length'] = df_with_gt['close_notes'].astype(str).str.len()\n",
    "            df_with_gt['close_notes_word_count'] = df_with_gt['close_notes'].astype(str).str.split().str.len()\n",
    "            \n",
    "            print(f\"\\nüìã Resolution Notes (close_notes) Statistics:\")\n",
    "            print(f\"   Average length: {df_with_gt['close_notes_length'].mean():.0f} characters\")\n",
    "            print(f\"   Median length: {df_with_gt['close_notes_length'].median():.0f} characters\")\n",
    "            print(f\"   Average word count: {df_with_gt['close_notes_word_count'].mean():.0f} words\")\n",
    "            print(f\"   Range: {df_with_gt['close_notes_length'].min()} - {df_with_gt['close_notes_length'].max()} characters\")\n",
    "            \n",
    "            # Expansion ratio\n",
    "            expansion_ratio = df_with_gt['close_notes_length'].mean() / df_with_gt['content_length'].mean()\n",
    "            print(f\"\\nüìà Content Expansion:\")\n",
    "            print(f\"   Resolution notes are {expansion_ratio:.2f}x longer than input content on average\")\n",
    "            \n",
    "            if 'info_score_close_notes' in df_with_gt.columns:\n",
    "                info_scores = df_with_gt['info_score_close_notes'].dropna()\n",
    "                if len(info_scores) > 0:\n",
    "                    print(f\"\\n‚≠ê Information Quality Score:\")\n",
    "                    print(f\"   Mean: {info_scores.mean():.2f}\")\n",
    "                    print(f\"   Median: {info_scores.median():.2f}\")\n",
    "                    print(f\"   Range: {info_scores.min():.2f} - {info_scores.max():.2f}\")\n",
    "                    high_quality = (info_scores >= 0.8).sum()\n",
    "                    print(f\"   High quality (‚â•0.8): {high_quality} ({high_quality/len(info_scores)*100:.1f}%)\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Prepare Data for Next Steps\n",
    "\n",
    "**What we're doing:** Filtering and preparing the data for the rest of the workshop.\n",
    "\n",
    "**Why:** \n",
    "- We want to focus on incidents that have close notes (so we can compare AI-generated ones to real ones)\n",
    "- We need clean, ready-to-use data for the next notebooks\n",
    "- This is like organizing your workspace before starting a project\n",
    "\n",
    "**What we'll do:**\n",
    "- Keep only incidents that have close notes (our \"ground truth\" examples)\n",
    "- These will be used in later notebooks to evaluate AI-generated close notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter incidents that have close_notes (ground truth) for evaluation\n",
    "# We only want incidents that have close notes because we'll use those as examples\n",
    "# to compare against AI-generated close notes\n",
    "\n",
    "if 'close_notes' in df.columns:\n",
    "    df_with_ground_truth = df[df['close_notes'].notna()].copy()\n",
    "    print(\"üìä Filtering incidents:\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"‚úÖ Incidents WITH close notes (ground truth): {len(df_with_ground_truth)}\")\n",
    "    print(f\"‚ùå Incidents WITHOUT close notes: {len(df) - len(df_with_ground_truth)}\")\n",
    "    \n",
    "    # For experiments, we'll use incidents with ground truth\n",
    "    df_experiments = df_with_ground_truth.copy()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No close_notes column found - will use all incidents\")\n",
    "    df_experiments = df.copy()\n",
    "\n",
    "print(f\"\\nüéØ Total incidents prepared for experiments: {len(df_experiments)}\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Prepared Dataset\n",
    "\n",
    "**What we're doing:** Saving our prepared data to a file so we can use it in the next notebooks.\n",
    "\n",
    "**Why:** The next notebooks need this data, and it's easier to load from a file than to reload everything each time.\n",
    "\n",
    "**Think of it like:** Saving your work so you can come back to it later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "# This is where we'll save our prepared data files\n",
    "\n",
    "data_dir = Path(\"../data\")\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save the prepared dataset (all incidents with close notes)\n",
    "output_path = data_dir / \"incidents_prepared.csv\"\n",
    "df_experiments.to_csv(output_path, index=False)\n",
    "print(\"üíæ Saving datasets:\")\n",
    "print(\"=\"*80)\n",
    "print(f\"‚úÖ Saved FULL prepared dataset to: {output_path}\")\n",
    "print(f\"   Total records: {len(df_experiments)} incidents\")\n",
    "\n",
    "# Also save a small sample for quick testing (useful for faster experiments)\n",
    "df_sample = df_experiments.sample(min(10, len(df_experiments)), random_state=42)\n",
    "sample_path = data_dir / \"incidents_sample.csv\"\n",
    "df_sample.to_csv(sample_path, index=False)\n",
    "print(f\"\\n‚úÖ Saved SAMPLE dataset to: {sample_path}\")\n",
    "print(f\"   Sample records: {len(df_sample)} incidents (for quick testing)\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary - What We Accomplished\n",
    "\n",
    "**Congratulations!** üéâ You've completed your first notebook. Here's what we did:\n",
    "\n",
    "‚úÖ **Loaded the dataset** - Got 200 IT incident tickets from Hugging Face  \n",
    "‚úÖ **Explored the data** - Saw what information each incident contains  \n",
    "‚úÖ **Analyzed patterns** - Learned about categories, types, and resolution times  \n",
    "‚úÖ **Checked quality** - Identified which incidents have good close notes  \n",
    "‚úÖ **Prepared the data** - Filtered and saved it for the next notebooks  \n",
    "\n",
    "**What you learned:**\n",
    "- How to load and explore a dataset\n",
    "- What information IT incidents contain\n",
    "- How to visualize data patterns\n",
    "- What makes a good close note (detailed, informative)\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "**Ready for Notebook 02!** \n",
    "\n",
    "In the next notebook, we'll:\n",
    "- Define what makes a \"good\" close note\n",
    "- Separate high-quality close notes from regular ones\n",
    "- Create reference examples that we'll use to evaluate AI-generated close notes\n",
    "\n",
    "**Files ready for next notebook:**\n",
    "- `data/incidents_prepared.csv` - All incidents with close notes\n",
    "- `data/incidents_sample.csv` - Small sample for quick testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ NOTEBOOK 01 COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nüìä Dataset loaded: {len(df)} total records\")\n",
    "print(f\"üìù Prepared for experiments: {len(df_experiments)} records (with close notes)\")\n",
    "print(f\"üíæ Saved to: {output_path}\")\n",
    "print(f\"\\n‚ú® What's next?\")\n",
    "print(f\"   ‚Üí Move to Notebook 02: Create Ground Truth\")\n",
    "print(f\"   ‚Üí We'll identify high-quality close notes to use as reference examples\")\n",
    "print(\"\\n‚úÖ Ready for the next notebook!\")\n",
    "print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
