# ğŸ§  AI Test Drive â€“ CenÃ¡rio 2: Enriquecendo Incidentes com IA

## ğŸ¯ Objetivo

Este exercÃ­cio prÃ¡tico demonstra **como aplicar modelos de IA (LLMs)** para **enriquecer informaÃ§Ãµes de incidentes** em sistemas de ITSM (ex: ServiceNow) e **reduzir o Mean Time To Detect (MTTD)**.
A proposta Ã© **simples, interativa e lÃºdica**, permitindo explorar **diferentes prompts, modelos e pipelines de avaliaÃ§Ã£o** com as ferramentas da **plataforma Red Hat**.

---

## ğŸ§© O que vocÃª vai aprender

* Como **preparar e explorar um dataset de incidentes** simulados.
* Como **usar LLMs para completar informaÃ§Ãµes faltantes** em registros.
* Como **testar e comparar prompts e modelos** dentro do OpenShift AI.
* Como **avaliar resultados com mÃ©tricas de qualidade** usando **TrustyAI** e **MLflow**.
* Como **estruturar um pipeline de experimentos reprodutÃ­vel e rastreÃ¡vel**.

---

## ğŸ§± Estrutura do RepositÃ³rio

```
ai-testdrive-scenario2/
â”œâ”€â”€ README.md
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ incidents_raw.csv
â”‚   â”œâ”€â”€ incidents_enriched_groundtruth.csv
â”‚   â””â”€â”€ prompts/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_load_and_explore_dataset.ipynb
â”‚   â”œâ”€â”€ 02_prompt_experiments.ipynb
â”‚   â”œâ”€â”€ 03_llm_eval_with_trustyai.ipynb
â”‚   â”œâ”€â”€ 04_mlflow_tracking.ipynb
â”‚   â””â”€â”€ 05_summary_and_results.ipynb
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py
â”‚   â”œâ”€â”€ prompts.py
â”‚   â”œâ”€â”€ evaluator.py
â”‚   â””â”€â”€ mlflow_tracking.py
â””â”€â”€ requirements.txt
```

---

## ğŸ§ª Fluxo de ExecuÃ§Ã£o

1. **Explorar o dataset** de incidentes incompletos.
2. **Aplicar diferentes prompts** para gerar versÃµes enriquecidas via LLM.
3. **Comparar e avaliar** as respostas com base em precisÃ£o, clareza e consistÃªncia.
4. **Rastrear os resultados** com MLflow e TrustyAI.
5. **Discutir insights e boas prÃ¡ticas** de IA corporativa.

---

## ğŸ“š Dataset â€“ Synthetic IT Call Center Tickets

**Fonte:**
[ğŸ”— Hugging Face â€“ KameronB/synthetic-it-callcenter-tickets](https://huggingface.co/datasets/KameronB/synthetic-it-callcenter-tickets)

Este dataset contÃ©m **tickets sintÃ©ticos de um call center de TI**, simulando incidentes e requisiÃ§Ãµes em sistemas corporativos (como ServiceNow).
Ele Ã© ideal para demonstrar tarefas de **classificaÃ§Ã£o, enriquecimento e correlaÃ§Ã£o de incidentes** usando modelos de linguagem.

---

### ğŸ§¾ Estrutura dos Dados

Cada registro representa um ticket (incidente ou requisiÃ§Ã£o).
Abaixo estÃ£o as colunas principais â€” Ãºteis para os exercÃ­cios de enriquecimento e anÃ¡lise de similaridade:

| Coluna                        | Tipo       | DescriÃ§Ã£o                                                              |
| ----------------------------- | ---------- | ---------------------------------------------------------------------- |
| `number`                      | `string`   | Identificador Ãºnico do ticket (ex: INC0048604, TASK0049212).           |
| `date`                        | `datetime` | Data/hora de abertura do chamado.                                      |
| `contact_type`                | `string`   | Canal de contato (Chat, Email, Phone, Portal).                         |
| `short_description`           | `string`   | Resumo breve do problema ou solicitaÃ§Ã£o.                               |
| `content`                     | `string`   | Texto completo da descriÃ§Ã£o do ticket â€” usado como input do LLM.       |
| `category`                    | `string`   | Categoria principal (SOFTWARE, HARDWARE, NETWORK, etc.).               |
| `subcategory`                 | `string`   | Subcategoria mais especÃ­fica (INSTALLATION, ERROR, PERFORMANCE, etc.). |
| `customer`                    | `string`   | Nome do solicitante (sintÃ©tico).                                       |
| `resolved_at`                 | `datetime` | Data/hora de resoluÃ§Ã£o.                                                |
| `close_notes`                 | `string`   | Texto do fechamento do ticket (usado como â€œresposta verdadeiraâ€).      |
| `agent`                       | `string`   | Nome do atendente responsÃ¡vel (sintÃ©tico).                             |
| `reassigned_count`            | `int`      | NÃºmero de reatribuiÃ§Ãµes entre equipes.                                 |
| `resolution_time`             | `float`    | Tempo total de resoluÃ§Ã£o (em minutos).                                 |
| `issue/request`               | `string`   | Tipo de demanda (Incident / Request).                                  |
| `software/system`             | `string`   | Sistema ou aplicaÃ§Ã£o afetada.                                          |
| `assignment_group`            | `string`   | Grupo responsÃ¡vel pelo atendimento.                                    |
| `info_score_close_notes`      | `float`    | Indicador da qualidade informacional das notas de fechamento.          |
| `info_score_poor_close_notes` | `float`    | Indicador da falta de informaÃ§Ãµes Ãºteis.                               |

> ğŸ’¡ **Dica:** as colunas `content` e `close_notes` sÃ£o as mais importantes para o cenÃ¡rio de *enriquecimento de incidentes*, pois representam o antes/depois da atuaÃ§Ã£o do LLM.

---

### ğŸ§© Exemplo de Registro

| Campo                 | Valor                                                                                                                                 |
| --------------------- | ------------------------------------------------------------------------------------------------------------------------------------- |
| **number**            | `INC0048604`                                                                                                                          |
| **date**              | `3/27/2021 10:09`                                                                                                                     |
| **contact_type**      | `Email`                                                                                                                               |
| **short_description** | `ZTrend crashes unexpectedly when saving files`                                                                                       |
| **content**           | `User reports ZTrend crashes unexpectedly when attempting to save files. Performed initial diagnostics...`                            |
| **category**          | `SOFTWARE`                                                                                                                            |
| **subcategory**       | `ERROR`                                                                                                                               |
| **close_notes**       | `Performed diagnostics and identified corrupted config files. Cleared cache, reinstalled app, and restored defaults. Issue resolved.` |
| **agent**             | `Watson, Samuel`                                                                                                                      |
| **resolution_time**   | `876.01` minutes                                                                                                                      |

---

### âš™ï¸ Como carregar o dataset no notebook

```python
from datasets import load_dataset

dataset = load_dataset("KameronB/synthetic-it-callcenter-tickets")
df = dataset["train"].to_pandas()

df.head()
```

Para reduzir a carga durante o teste, vocÃª pode usar uma amostra pequena:

```python
df = df.sample(200, random_state=42)
```

Perfeito ğŸ‘Œ â€” o **Langfuse** Ã© parte essencial do stack moderno de observabilidade e rastreabilidade de LLMs, entÃ£o ele deve aparecer junto das demais ferramentas de monitoramento e experimentaÃ§Ã£o.
Aqui estÃ¡ a versÃ£o atualizada da seÃ§Ã£o â€œâš™ï¸ Ferramentas Envolvidasâ€, jÃ¡ com **Langfuse** incluÃ­do e descrito de forma alinhada com as demais tecnologias da Red Hat AI stack:

---

## âš™ï¸ Ferramentas Envolvidas

* ğŸ§  **OpenShift AI** â€“ ambiente unificado para desenvolvimento, execuÃ§Ã£o e gestÃ£o de notebooks, modelos e pipelines de IA, com escalabilidade e seguranÃ§a corporativa.
* ğŸ§© **TrustyAI** â€“ conjunto de ferramentas para **avaliaÃ§Ã£o de qualidade, fairness, explicabilidade e confiabilidade** de modelos de IA, integrÃ¡vel com o ecossistema Red Hat.
* ğŸ“ˆ **MLflow** â€“ plataforma para **rastreamento e comparaÃ§Ã£o de experimentos**, versionamento de modelos e monitoramento de mÃ©tricas de performance durante o ciclo de vida da IA.
* ğŸ§¾ **Langfuse** â€“ ferramenta de **observabilidade e tracing de LLMs**, utilizada para:

  * registrar e visualizar prompts, respostas e tempos de execuÃ§Ã£o;
  * comparar desempenho entre diferentes versÃµes de prompts e modelos;
  * integrar mÃ©tricas de qualidade (ex.: *factual consistency*, *latÃªncia*, *custo*) com o pipeline de MLflow;
  * gerar dashboards de uso e impacto das aplicaÃ§Ãµes baseadas em IA.
* ğŸ“¦ **LangChain / Hugging Face** â€“ bibliotecas para **integraÃ§Ã£o, orquestraÃ§Ã£o e execuÃ§Ã£o de modelos de linguagem (LLMs)** e manipulaÃ§Ã£o de datasets pÃºblicos, incluindo o *Synthetic IT Call Center Tickets*.

---

## ğŸ’¡ Valor Demonstrado

Este exercÃ­cio mostra, de forma prÃ¡tica, como **um modelo pequeno e governado** pode superar um **LLM genÃ©rico** em precisÃ£o e custo â€” destacando a **forÃ§a do ecossistema Red Hat AI** em **controle, auditabilidade e eficiÃªncia**.

