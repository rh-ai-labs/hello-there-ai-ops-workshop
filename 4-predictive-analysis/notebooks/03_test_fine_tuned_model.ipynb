{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste do Modelo com Fine-tuning\n",
    "\n",
    "Este notebook demonstra como carregar e testar o modelo que foi submetido a fine-tuning usando LoRA.\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Testar o modelo treinado para extrair campos estruturados de tickets de call center, verificando se o fine-tuning melhorou a capacidade do modelo de retornar dados em formato JSON.\n",
    "\n",
    "## Estrutura do Notebook\n",
    "\n",
    "1. **Carregamento do Modelo**: Carrega o modelo base e o adaptador LoRA treinado\n",
    "2. **Prepara√ß√£o do Tokenizer**: Configura o tokenizer para processar as entradas\n",
    "3. **Testes com Exemplos**: Testa o modelo com diferentes exemplos de tickets\n",
    "4. **Avalia√ß√£o**: Compara as respostas do modelo com os resultados esperados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configura√ß√£o e Importa√ß√µes\n",
    "\n",
    "Configuramos os caminhos e importamos as bibliotecas necess√°rias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa√ß√µes necess√°rias\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel\n",
    "import json\n",
    "import re\n",
    "\n",
    "# -------------------------------\n",
    "# CONFIGURA√á√ÉO\n",
    "# -------------------------------\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-3B-Instruct\"  # Modelo base\n",
    "LORA_ADAPTER_PATH = \"./qwen2.5-lora\"  # Caminho do adaptador LoRA treinado\n",
    "\n",
    "print(\"Configura√ß√£o carregada:\")\n",
    "print(f\"  Modelo base: {MODEL_NAME}\")\n",
    "print(f\"  Adaptador LoRA: {LORA_ADAPTER_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento do Tokenizer\n",
    "\n",
    "Carregamos o tokenizer que ser√° usado para processar as entradas e sa√≠das do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar tokenizer\n",
    "print(\"Carregando tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    trust_remote_code=True,\n",
    "    use_auth_token=True\n",
    ")\n",
    "\n",
    "# Configurar padding token se necess√°rio\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "print(\"‚úì Tokenizer carregado com sucesso\")\n",
    "print(f\"  Tamanho do vocabul√°rio: {len(tokenizer)}\")\n",
    "print(f\"  Token de padding: {tokenizer.pad_token}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Carregamento do Modelo Base e Adaptador LoRA\n",
    "\n",
    "Carregamos o modelo base e depois aplicamos o adaptador LoRA treinado. O adaptador cont√©m apenas os pesos ajustados durante o fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo base\n",
    "print(\"Carregando modelo base...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    trust_remote_code=True,\n",
    "    use_auth_token=True\n",
    ")\n",
    "\n",
    "print(\"‚úì Modelo base carregado\")\n",
    "\n",
    "# Carregar adaptador LoRA treinado\n",
    "print(f\"\\nCarregando adaptador LoRA de {LORA_ADAPTER_PATH}...\")\n",
    "model = PeftModel.from_pretrained(model, LORA_ADAPTER_PATH)\n",
    "\n",
    "print(\"‚úì Adaptador LoRA carregado com sucesso\")\n",
    "\n",
    "# Colocar modelo em modo de avalia√ß√£o (n√£o treinamento)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  Modelo no dispositivo: {next(model.parameters()).device}\")\n",
    "else:\n",
    "    print(\"  Modelo na CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Fun√ß√£o de Infer√™ncia\n",
    "\n",
    "Criamos uma fun√ß√£o auxiliar para fazer infer√™ncia com o modelo, formatando a entrada e processando a sa√≠da.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, max_new_tokens=512, temperature=0.1, top_p=0.9):\n",
    "    \"\"\"\n",
    "    Gera uma resposta do modelo para um prompt dado.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Texto de entrada (descri√ß√£o do ticket)\n",
    "        max_new_tokens: N√∫mero m√°ximo de tokens a gerar\n",
    "        temperature: Controla a aleatoriedade (menor = mais determin√≠stico)\n",
    "        top_p: Nucleus sampling (probabilidade acumulada)\n",
    "    \n",
    "    Returns:\n",
    "        Resposta gerada pelo modelo\n",
    "    \"\"\"\n",
    "    # Formatar prompt no formato esperado pelo modelo\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    # Aplicar template de chat do tokenizer\n",
    "    if hasattr(tokenizer, 'apply_chat_template') and tokenizer.chat_template is not None:\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "    else:\n",
    "        # Fallback: formata√ß√£o manual\n",
    "        formatted_prompt = f\"<|im_start|>user\\n{prompt}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "    \n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Mover para o mesmo dispositivo do modelo\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "    \n",
    "    # Gerar resposta\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "            do_sample=temperature > 0,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    # Decodificar resposta (remover o prompt da sa√≠da)\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=False)\n",
    "    \n",
    "    # Extrair apenas a parte gerada (ap√≥s o prompt)\n",
    "    if \"<|im_start|>assistant\" in generated_text:\n",
    "        response = generated_text.split(\"<|im_start|>assistant\")[-1]\n",
    "        response = response.replace(\"<|im_end|>\", \"\").strip()\n",
    "    else:\n",
    "        # Se n√£o encontrar o marcador, pegar tudo ap√≥s o prompt\n",
    "        prompt_tokens = len(tokenizer.encode(formatted_prompt))\n",
    "        response = tokenizer.decode(outputs[0][prompt_tokens:], skip_special_tokens=True)\n",
    "    \n",
    "    return response\n",
    "\n",
    "print(\"‚úì Fun√ß√£o de infer√™ncia criada\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testes com Exemplos\n",
    "\n",
    "Testamos o modelo com diferentes exemplos de tickets para verificar se ele consegue extrair os campos corretamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos de teste\n",
    "test_examples = [\n",
    "    {\n",
    "        \"name\": \"Exemplo 1: Upgrade de PostgreSQL\",\n",
    "        \"prompt\": (\n",
    "            \"Short description: Request for PostgreSQL upgrade to the latest version.\\n\"\n",
    "            \"Content: I would like to request an upgrade for our PostgreSQL to the latest version \"\n",
    "            \"in order to utilize new features and improvements. Before proceeding, please assess \"\n",
    "            \"the impact this upgrade may have on our current projects and confirm compatibility \"\n",
    "            \"with our existing data. Could you escalate this request to the Software Upgrade Team for me?\\n\"\n",
    "            \"Preencha os seguintes campos em JSON:\\n\"\n",
    "            \"- category\\n\"\n",
    "            \"- subcategory\\n\"\n",
    "            \"- issue_request\\n\"\n",
    "            \"- assignment_group\\n\"\n",
    "            \"- software_system\\n\"\n",
    "            \"- poor_close_notes\\n\"\n",
    "            \"- resolution_time\\n\"\n",
    "            \"- info_score_close_notes\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Exemplo 2: Problema de Login\",\n",
    "        \"prompt\": (\n",
    "            \"Short description: User unable to login to system\\n\"\n",
    "            \"Content: I am experiencing issues logging into the company portal. \"\n",
    "            \"I have tried resetting my password multiple times but still cannot access my account. \"\n",
    "            \"The error message says 'Invalid credentials' but I am certain I am using the correct password.\\n\"\n",
    "            \"Preencha os seguintes campos em JSON:\\n\"\n",
    "            \"- category\\n\"\n",
    "            \"- subcategory\\n\"\n",
    "            \"- issue_request\\n\"\n",
    "            \"- assignment_group\\n\"\n",
    "            \"- software_system\\n\"\n",
    "            \"- poor_close_notes\\n\"\n",
    "            \"- resolution_time\\n\"\n",
    "            \"- info_score_close_notes\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Exemplo 3: Aplica√ß√£o com Crash\",\n",
    "        \"prompt\": (\n",
    "            \"Short description: Application crashes when saving files\\n\"\n",
    "            \"Content: The application ZTrend keeps crashing whenever I try to save a file. \"\n",
    "            \"This started happening after the last system update. I have lost work multiple times. \"\n",
    "            \"Please help me resolve this issue as soon as possible.\\n\"\n",
    "            \"Preencha os seguintes campos em JSON:\\n\"\n",
    "            \"- category\\n\"\n",
    "            \"- subcategory\\n\"\n",
    "            \"- issue_request\\n\"\n",
    "            \"- assignment_group\\n\"\n",
    "            \"- software_system\\n\"\n",
    "            \"- poor_close_notes\\n\"\n",
    "            \"- resolution_time\\n\"\n",
    "            \"- info_score_close_notes\"\n",
    "        )\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Preparados {len(test_examples)} exemplos para teste\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar testes\n",
    "print(\"=\" * 80)\n",
    "print(\"EXECUTANDO TESTES DO MODELO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, example in enumerate(test_examples, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TESTE {i}: {example['name']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(\"\\nüì• Prompt:\")\n",
    "    print(example['prompt'][:200] + \"...\" if len(example['prompt']) > 200 else example['prompt'])\n",
    "    \n",
    "    print(\"\\nü§ñ Gerando resposta...\")\n",
    "    try:\n",
    "        response = generate_response(example['prompt'])\n",
    "        \n",
    "        print(\"\\nüì§ Resposta do modelo:\")\n",
    "        print(response)\n",
    "        \n",
    "        # Tentar parsear como JSON\n",
    "        try:\n",
    "            # Limpar a resposta (remover markdown code blocks se houver)\n",
    "            cleaned_response = response.strip()\n",
    "            if cleaned_response.startswith(\"```\"):\n",
    "                # Remover code blocks\n",
    "                lines = cleaned_response.split(\"\\n\")\n",
    "                cleaned_response = \"\\n\".join([l for l in lines if not l.strip().startswith(\"```\")])\n",
    "            \n",
    "            parsed_json = json.loads(cleaned_response)\n",
    "            print(\"\\n‚úÖ Resposta v√°lida em formato JSON:\")\n",
    "            print(json.dumps(parsed_json, indent=2, ensure_ascii=False))\n",
    "            \n",
    "            results.append({\n",
    "                \"test\": example['name'],\n",
    "                \"success\": True,\n",
    "                \"response\": response,\n",
    "                \"parsed_json\": parsed_json\n",
    "            })\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"\\n‚ö†Ô∏è  Resposta n√£o √© JSON v√°lido: {e}\")\n",
    "            print(f\"   Tentando extrair JSON da resposta...\")\n",
    "            \n",
    "            # Tentar encontrar JSON na resposta\n",
    "            json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "            if json_match:\n",
    "                try:\n",
    "                    parsed_json = json.loads(json_match.group())\n",
    "                    print(\"\\n‚úÖ JSON extra√≠do com sucesso:\")\n",
    "                    print(json.dumps(parsed_json, indent=2, ensure_ascii=False))\n",
    "                    results.append({\n",
    "                        \"test\": example['name'],\n",
    "                        \"success\": True,\n",
    "                        \"response\": response,\n",
    "                        \"parsed_json\": parsed_json\n",
    "                    })\n",
    "                except:\n",
    "                    results.append({\n",
    "                        \"test\": example['name'],\n",
    "                        \"success\": False,\n",
    "                        \"response\": response,\n",
    "                        \"error\": \"N√£o foi poss√≠vel parsear JSON\"\n",
    "                    })\n",
    "            else:\n",
    "                results.append({\n",
    "                    \"test\": example['name'],\n",
    "                    \"success\": False,\n",
    "                    \"response\": response,\n",
    "                    \"error\": \"Nenhum JSON encontrado na resposta\"\n",
    "                })\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Erro durante a gera√ß√£o: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        results.append({\n",
    "            \"test\": example['name'],\n",
    "            \"success\": False,\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Resumo dos Resultados\n",
    "\n",
    "Exibimos um resumo dos testes realizados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo dos resultados\n",
    "print(\"=\" * 80)\n",
    "print(\"RESUMO DOS TESTES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "total_tests = len(results)\n",
    "successful_tests = sum(1 for r in results if r.get('success', False))\n",
    "failed_tests = total_tests - successful_tests\n",
    "\n",
    "print(f\"\\nTotal de testes: {total_tests}\")\n",
    "print(f\"‚úÖ Sucessos: {successful_tests}\")\n",
    "print(f\"‚ùå Falhas: {failed_tests}\")\n",
    "if total_tests > 0:\n",
    "    print(f\"üìä Taxa de sucesso: {successful_tests/total_tests*100:.1f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DETALHES POR TESTE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    status = \"‚úÖ\" if result.get('success', False) else \"‚ùå\"\n",
    "    print(f\"\\n{status} Teste {i}: {result['test']}\")\n",
    "    \n",
    "    if result.get('success'):\n",
    "        print(f\"   Campos extra√≠dos: {list(result.get('parsed_json', {}).keys())}\")\n",
    "    else:\n",
    "        print(f\"   Erro: {result.get('error', 'Desconhecido')}\")\n",
    "        if 'response' in result:\n",
    "            print(f\"   Resposta: {result['response'][:100]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Teste Interativo\n",
    "\n",
    "Voc√™ pode testar o modelo com seus pr√≥prios exemplos aqui. Modifique o prompt abaixo para testar diferentes casos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste interativo - modifique o prompt abaixo\n",
    "custom_prompt = \"\"\"\n",
    "Short description: [Sua descri√ß√£o curta aqui]\n",
    "Content: [Descri√ß√£o detalhada do problema ou solicita√ß√£o]\n",
    "Preencha os seguintes campos em JSON:\n",
    "- category\n",
    "- subcategory\n",
    "- issue_request\n",
    "- assignment_group\n",
    "- software_system\n",
    "- poor_close_notes\n",
    "- resolution_time\n",
    "- info_score_close_notes\n",
    "\"\"\"\n",
    "\n",
    "print(\"Testando com prompt customizado...\")\n",
    "print(\"\\nüì• Prompt:\")\n",
    "print(custom_prompt)\n",
    "\n",
    "response = generate_response(custom_prompt)\n",
    "\n",
    "print(\"\\nüì§ Resposta do modelo:\")\n",
    "print(response)\n",
    "\n",
    "# Tentar parsear JSON\n",
    "try:\n",
    "    json_match = re.search(r'\\{.*\\}', response, re.DOTALL)\n",
    "    if json_match:\n",
    "        parsed = json.loads(json_match.group())\n",
    "        print(\"\\n‚úÖ JSON extra√≠do:\")\n",
    "        print(json.dumps(parsed, indent=2, ensure_ascii=False))\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è  Nenhum JSON encontrado na resposta\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è  N√£o foi poss√≠vel extrair JSON: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
