{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a461a497"
   },
   "source": [
    "# Notebook 01: Build a Decision Tree for Tennis Club Predictions\n",
    "\n",
    "## ğŸ¯ Your Mission\n",
    "\n",
    "You're the AI engineer for a tennis club. Your job today: build a model that decides whether they should play tennis based on weather conditions.\n",
    "\n",
    "**Why this matters:** This same decision tree structure is how you could detect whether an incident should be escalated based on system metrics, or automatically route IT tickets to the right team.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ Quick Win (First 2 Minutes)\n",
    "\n",
    "Let's see a decision tree in action! Run the cell below to see how the model makes decisions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv(\"../data/play_tennis.csv\")\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df_encoded = df.apply(label_encoder.fit_transform)\n",
    "X = df_encoded[['Outlook', 'Temprature', 'Humidity', 'Wind']]\n",
    "y = df_encoded['Play_Tennis']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Train and visualize\n",
    "classifier = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plot_tree(classifier, filled=True, rounded=True, feature_names=['Outlook', 'Temprature', 'Humidity', 'Wind'], \n",
    "          class_names=[\"No\", \"Yes\"], fontsize=9)\n",
    "plt.title(\"Decision Tree: How the Model Makes Decisions\", fontsize=14, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ¯ This tree learned automatically from weather data!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What you just saw:** A decision tree that asks questions (like \"Is it sunny?\") and follows branches to make predictions. The algorithm learned this automatically from data!\n",
    "\n",
    "Now let's build it step by step to understand how it works.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ What You'll Learn\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "- âœ… Build a decision tree that predicts tennis play decisions\n",
    "- âœ… Understand how machine learning learns patterns from data\n",
    "- âœ… See how this applies to IT operations (incident classification, ticket routing)\n",
    "\n",
    "**Time:** ~10-15 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ The Journey\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bc248307"
   },
   "source": [
    "### Step 1: Load the Data\n",
    "\n",
    "**What we're doing:** Loading weather data from the tennis club's records.\n",
    "\n",
    "**Why:** We need historical data to teach the model what weather conditions lead to playing tennis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba483808",
    "outputId": "f06831bb-f62d-4c7e-98f9-aaf65ae1304b"
   },
   "outputs": [],
   "source": [
    "# Import our toolkit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/play_tennis.csv\")\n",
    "feature_cols = ['Outlook', 'Temprature', 'Humidity', 'Wind']\n",
    "\n",
    "print(f\"ğŸ“Š Loaded {len(df)} days of tennis data\")\n",
    "print(f\"ğŸ“‹ Dataset shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "print(f\"\\nğŸ” Let's examine the dataset:\")\n",
    "print(\"=\" * 60)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c5581666"
   },
   "source": [
    "**What we see in the dataset:**\n",
    "- **14 days** of historical weather and tennis play data\n",
    "- **Features** (what we'll use to predict): `Outlook`, `Temprature`, `Humidity`, `Wind`\n",
    "- **Target** (what we want to predict): `Play_Tennis` (Yes or No)\n",
    "\n",
    "**ğŸ’¡ Can you spot the patterns?** \n",
    "- Look at sunny days with weak wind â†’ mostly \"Yes\" for playing tennis\n",
    "- Look at rainy days â†’ mostly \"No\" for playing tennis\n",
    "- The decision tree will learn these patterns automatically!\n",
    "\n",
    "Let's see some statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataset statistics and patterns\n",
    "print(\"ğŸ“Š Dataset Overview:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nğŸ¾ Play Tennis Distribution:\")\n",
    "print(df['Play_Tennis'].value_counts())\n",
    "print(f\"\\nğŸ“ˆ Play Tennis Rate: {(df['Play_Tennis'] == 'Yes').sum()}/{len(df)} ({(df['Play_Tennis'] == 'Yes').sum()/len(df):.0%})\")\n",
    "\n",
    "print(f\"\\nğŸŒ¤ï¸  Weather Patterns:\")\n",
    "print(\"\\nOutlook distribution:\")\n",
    "print(df.groupby(['Outlook', 'Play_Tennis']).size().unstack(fill_value=0))\n",
    "\n",
    "print(\"\\nğŸ’¨ Wind distribution:\")\n",
    "print(df.groupby(['Wind', 'Play_Tennis']).size().unstack(fill_value=0))\n",
    "\n",
    "print(\"\\nğŸ’¡ Notice: The algorithm will learn these patterns automatically!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Prepare the Data\n",
    "\n",
    "**What we're doing:** Converting text categories (like \"Sunny\", \"Rainy\") to numbers that the algorithm can understand.\n",
    "\n",
    "**Why this matters:** Machine learning algorithms are mathematical - they work with numbers, not text. Think of this as translating between human language (\"Sunny\", \"Rainy\") and computer language (0, 1, 2).\n",
    "\n",
    "**The process:**\n",
    "1. **Label Encoding** - Convert text categories to numbers (e.g., \"Sunny\" â†’ 2, \"Rainy\" â†’ 1, \"Overcast\" â†’ 0)\n",
    "2. **Split Features and Target** - Separate what we use to predict (X: weather conditions) from what we want to predict (y: Play_Tennis)\n",
    "3. **Train/Test Split** - Divide data so the model learns on one set (70%) and we test on another (30%) to see if it actually learned patterns\n",
    "\n",
    "**ğŸ’¡ Key Concept:** The train/test split is crucial! It tells us if the model learned real patterns or just memorized the training examples. This is how we verify the model will work on new, unseen data.\n",
    "\n",
    "Let's see the transformation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c07eed83"
   },
   "outputs": [],
   "source": [
    "# Step 1: Convert text categories to numbers using LabelEncoder\n",
    "# \"Sunny\" becomes 2, \"Rainy\" becomes 1, \"Overcast\" becomes 0, etc.\n",
    "print(\"ğŸ”„ Step 1: Encoding text to numbers...\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nğŸ“‹ Original dataset (first 5 rows):\")\n",
    "print(df.head())\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df_encoded = df.apply(label_encoder.fit_transform)\n",
    "\n",
    "print(\"\\nğŸ“‹ Encoded dataset (first 5 rows):\")\n",
    "print(df_encoded.head())\n",
    "\n",
    "print(\"\\nğŸ“ Encoding mapping:\")\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        unique_vals = df[col].unique()\n",
    "        encoded_vals = df_encoded[col].unique()\n",
    "        mapping = dict(zip(sorted(unique_vals), sorted(encoded_vals)))\n",
    "        print(f\"   {col}: {mapping}\")\n",
    "\n",
    "# Step 2: Split into features (X) and target (y)\n",
    "# X = what we use to make predictions (weather conditions)\n",
    "# y = what we want to predict (Play_Tennis: Yes or No)\n",
    "print(\"\\nğŸ”„ Step 2: Splitting features and target...\")\n",
    "X = df_encoded[feature_cols]\n",
    "y = df_encoded['Play_Tennis']\n",
    "\n",
    "print(f\"\\nğŸ“Š Features (X) - What we use to predict:\")\n",
    "print(X.head())\n",
    "print(f\"\\n   Shape: {X.shape[0]} samples Ã— {X.shape[1]} features\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Target (y) - What we want to predict:\")\n",
    "print(y.head())\n",
    "print(f\"\\n   Values: {y.unique()} (0=No, 1=Yes)\")\n",
    "\n",
    "# Step 3: Split into training (70%) and testing (30%) sets\n",
    "# We train on one set, test on another to verify the model learned real patterns\n",
    "print(\"\\nğŸ”„ Step 3: Splitting into training and testing sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "print(f\"\\nâœ¨ Data preparation complete!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“š Training set: {len(X_train)} days\")\n",
    "print(f\"   - Features shape: {X_train.shape}\")\n",
    "print(f\"   - Target distribution: {dict(y_train.value_counts())}\")\n",
    "print(f\"\\nğŸ§ª Testing set: {len(X_test)} days\")\n",
    "print(f\"   - Features shape: {X_test.shape}\")\n",
    "print(f\"   - Target distribution: {dict(y_test.value_counts())}\")\n",
    "print(f\"\\n   Ratio: {len(X_train)/len(X):.0%} training, {len(X_test)/len(X):.0%} testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "815b0f9a"
   },
   "source": [
    "**What happened:** \n",
    "- âœ… Text categories converted to numbers (e.g., \"Sunny\" â†’ 2)\n",
    "- âœ… Data split into features (X) and target (y)\n",
    "- âœ… Data divided into training (70%) and testing (30%) sets\n",
    "\n",
    "**ğŸ’¡ Why this matters:** The train/test split is one of the most important concepts in machine learning! \n",
    "- The model learns patterns from the **training set**\n",
    "- We evaluate it on the **test set** (data it's never seen)\n",
    "- This tells us if the model actually learned useful patterns or just memorized the training examples\n",
    "\n",
    "**Real-world analogy:** It's like studying for a test - if you memorize answers to specific questions, you'll fail on new questions. But if you understand the concepts, you'll do well on any question. The test set checks if our model \"understands\" or just \"memorized.\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Train the Decision Tree\n",
    "\n",
    "**What we're doing:** Teaching the algorithm to learn patterns from the training data. This is where the magic happens - the computer discovers which questions to ask and in what order!\n",
    "\n",
    "**How it works:**\n",
    "1. **The algorithm starts** with all training examples\n",
    "2. **It tries different questions** (e.g., \"Is Outlook <= 0.5?\") to split the data\n",
    "3. **It picks the best question** - the one that creates the \"purest\" groups (mostly \"Yes\" or mostly \"No\")\n",
    "4. **It repeats** on each group until it reaches pure groups or hits a stopping condition\n",
    "\n",
    "**Why entropy:** We're using \"entropy\" as our splitting criterion. Entropy measures how \"mixed\" or \"uncertain\" a group is:\n",
    "- **Low entropy** = Pure group (all \"Yes\" or all \"No\") âœ…\n",
    "- **High entropy** = Mixed group (half \"Yes\", half \"No\") âŒ\n",
    "\n",
    "The algorithm tries to create groups with low entropy by asking the best questions first.\n",
    "\n",
    "**ğŸ’¡ Key Concept:** The algorithm automatically figures out which features matter most and which questions to ask first. We don't tell it \"ask about Outlook first\" - it discovers that on its own!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "c2018b70",
    "outputId": "d2a311e0-543c-4c03-996d-ee1618e62e19"
   },
   "outputs": [],
   "source": [
    "# Step 1: Create the decision tree classifier\n",
    "# criterion=\"entropy\" means we want to minimize uncertainty in each split\n",
    "# random_state=42 ensures we get the same results every time (for reproducibility)\n",
    "print(\"ğŸ”„ Step 1: Creating the decision tree classifier...\")\n",
    "print(\"=\" * 60)\n",
    "classifier = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "print(\"âœ… Classifier created with entropy criterion\")\n",
    "\n",
    "# Step 2: Train the model - this is where it learns patterns!\n",
    "# The fit() method analyzes the training data and builds the decision tree\n",
    "print(\"\\nğŸ”„ Step 2: Training the model...\")\n",
    "print(f\"   The algorithm is now:\")\n",
    "print(f\"   - Analyzing {len(X_train)} training examples\")\n",
    "print(f\"   - Finding the best questions to ask\")\n",
    "print(f\"   - Building the decision tree structure...\")\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(\"âœ… Training complete!\")\n",
    "print(f\"   Tree built with {classifier.get_depth()} levels and {classifier.get_n_leaves()} decision points\")\n",
    "\n",
    "# Step 3: Make predictions on test data (data the model has never seen)\n",
    "# This tests whether the model learned real patterns or just memorized training examples\n",
    "print(\"\\nğŸ”„ Step 3: Making predictions on test data...\")\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Show predictions vs actual values\n",
    "print(\"\\nğŸ“Š Predictions vs Actual Values:\")\n",
    "print(\"=\" * 60)\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual': y_test.values,\n",
    "    'Predicted': y_pred,\n",
    "    'Correct': y_test.values == y_pred\n",
    "})\n",
    "comparison_df['Actual_Label'] = comparison_df['Actual'].map({0: 'No', 1: 'Yes'})\n",
    "comparison_df['Predicted_Label'] = comparison_df['Predicted'].map({0: 'No', 1: 'Yes'})\n",
    "print(comparison_df[['Actual_Label', 'Predicted_Label', 'Correct']].to_string(index=False))\n",
    "\n",
    "correct = comparison_df['Correct'].sum()\n",
    "total = len(comparison_df)\n",
    "print(f\"\\nâœ… Correct predictions: {correct}/{total}\")\n",
    "\n",
    "# Step 4: Evaluate the model's performance\n",
    "print(\"\\nğŸ”„ Step 4: Evaluating model performance...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "tree_depth = classifier.get_depth()\n",
    "num_leaves = classifier.get_n_leaves()\n",
    "\n",
    "print(\"\\nğŸ“ Model Evaluation Results:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"âœ… Accuracy: {accuracy:.0%} ({accuracy*100:.1f}% of predictions were correct)\")\n",
    "print(f\"ğŸ“ Tree structure:\")\n",
    "print(f\"   - Depth: {tree_depth} levels (how many questions it asks)\")\n",
    "print(f\"   - Leaves: {num_leaves} final decisions (end points)\")\n",
    "print(f\"\\nğŸ’¡ What this means: The model correctly predicted {accuracy:.0%} of the test cases!\")\n",
    "print(f\"   Out of {len(X_test)} test examples, {correct} were predicted correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f87b61de"
   },
   "source": [
    "**What happened:**\n",
    "- âœ… The decision tree algorithm analyzed the training data\n",
    "- âœ… It automatically determined which questions to ask first (e.g., \"Is Outlook <= 0.5?\")\n",
    "- âœ… It built a tree structure with multiple levels and decision points\n",
    "- âœ… It made predictions on the test set (check the accuracy above!)\n",
    "\n",
    "**ğŸ’¡ What this means:** The model learned patterns from the weather data! It can now predict whether to play tennis based on weather conditions. The accuracy percentage tells us how often it's correct on new, unseen data.\n",
    "\n",
    "**Key insight:** Notice how the algorithm automatically figured out which features matter most? It didn't need us to tell it \"check Outlook first\" - it discovered that through the data!\n",
    "\n",
    "**Next step:** Let's visualize the decision tree to see exactly how it makes these decisions - you'll be able to trace through the tree and understand its \"thought process\"!\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17ecac7d",
    "outputId": "efb683b1-38b7-4e4e-c9f6-5183134b3a41"
   },
   "source": [
    "### Step 4: Visualize the Decision Tree\n",
    "\n",
    "**What we're doing:** Creating a visual representation of how the model makes decisions.\n",
    "\n",
    "**Why this is cool:** You can actually SEE how the model thinks! Each node asks a question, each branch is an answer, and each leaf is a final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "081e1782",
    "outputId": "29673a7d-4ca3-4129-b281-a106ace7cc25"
   },
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    classifier,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    feature_names=feature_cols,\n",
    "    class_names=[\"No\", \"Yes\"],\n",
    "    fontsize=10\n",
    ")\n",
    "plt.title(\"Decision Tree Visualization\", fontsize=16, fontweight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"ğŸ’¡ How to read: Start at the top, follow branches based on conditions, end at a leaf with the prediction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "083372cd",
    "outputId": "53fd4869-dd76-4db3-e8b0-ea012ac883d9"
   },
   "source": [
    "**What happened:** You can see the decision tree! The algorithm automatically figured out which questions to ask first (Outlook, then Humidity) to make the best predictions.\n",
    "\n",
    "**ğŸ’¡ Insight:** This is machine learning - the computer learned the decision-making process from data, without us programming every rule.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ Key Takeaway\n",
    "\n",
    "A decision tree learns to make decisions by asking a series of questions. The algorithm automatically figures out which questions to ask first to create the most accurate predictions. You can see exactly how it thinks - making it perfect for understanding and trusting AI decisions.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "580a0e4a",
    "outputId": "bd6ab9ca-a3ee-4b92-a495-985c33d41a7f"
   },
   "source": [
    "## ğŸŒ Real-World Connection\n",
    "\n",
    "**How this applies to IT Operations:**\n",
    "\n",
    "The same decision tree approach can solve real IT problems. Instead of weather conditions, use system metrics, logs, and incident data:\n",
    "\n",
    "- **Incident Classification:** \"Is it affecting production?\" â†’ \"Is it user-reported?\" â†’ Automatically route tickets to the right team\n",
    "- **Failure Prediction:** \"Is CPU usage high?\" â†’ \"Is memory usage high?\" â†’ Predict which systems are likely to fail\n",
    "- **Change Risk Assessment:** \"Is it a production system?\" â†’ \"Is it during business hours?\" â†’ Evaluate deployment risk automatically\n",
    "\n",
    "The pattern is the same: ask questions, narrow down possibilities, make decisions based on patterns learned from historical data.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eb8ad25b"
   },
   "source": [
    "## âœ¨ Your Turn\n",
    "\n",
    "**Try this:** Change the `max_depth` parameter in the DecisionTreeClassifier (add `max_depth=2`) and see how it affects the tree! A smaller depth creates a simpler tree, but might be less accurate.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "classifier = DecisionTreeClassifier(criterion=\"entropy\", max_depth=2, random_state=42)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ You Did It!\n",
    "\n",
    "You've built your first machine learning model! The decision tree learned patterns from weather data and can now predict whether to play tennis. The concepts you learned here form the foundation for all the advanced AI techniques we'll explore in the next modules.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š Want to Go Deeper?\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ“¦ Installing Required Libraries (Click to expand)</summary>\n",
    "\n",
    "If you need to install libraries:\n",
    "\n",
    "```python\n",
    "%pip install matplotlib scikit-learn pandas numpy\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary>ğŸ“– Additional Resources (Click to expand)</summary>\n",
    "\n",
    "- [Scikit-learn Decision Trees Documentation](https://scikit-learn.org/stable/modules/tree.html) - Deep dive into decision trees\n",
    "- [OpenShift AI Documentation](https://access.redhat.com/documentation/en-us/red_hat_openshift_ai) - Enterprise AI platform\n",
    "- [Pandas Documentation](https://pandas.pydata.org/docs/) - Data manipulation library\n",
    "</details>\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
